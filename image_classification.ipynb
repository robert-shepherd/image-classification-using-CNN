{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSC Project 2431907s no hyper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q4hBW7_vIkr",
        "colab_type": "text"
      },
      "source": [
        "#LSC Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5GVJlnFvVSn",
        "colab_type": "text"
      },
      "source": [
        "##Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHC9nCUwvuja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "5342af0c-3995-44f7-ba54-e3d588703438"
      },
      "source": [
        "!pip install keras-tuner #Installing keras tuner-for hyperparameter optimisation\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from kerastuner import HyperModel\n",
        "\n",
        "plt.rcParams['savefig.transparent'] = True\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/f7/4b41b6832abf4c9bef71a664dc563adb25afc5812831667c6db572b1a261/keras-tuner-1.0.1.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.18.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.6.20)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.16.0)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-cp36-none-any.whl size=73200 sha256=b6f2509ba0a58204ae57f8977db9fd7c028c1a0cdf4bf8d87037897869b83406\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/cc/62/52716b70dd90f3db12519233c3a93a5360bc672da1a10ded43\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15356 sha256=795ca227abb85b687cfc1fc554c71c240fad22f62348a7bd81375bc6925be6ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.3 keras-tuner-1.0.1 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQxydPPrvcCV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a85e4682-e273-451d-9c3a-e5d799dd6edf"
      },
      "source": [
        "# Download CIFAR 100 with the 20 superclass labels \n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode='coarse') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMWz9WWB2LZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b26c75ab-824e-49a3-9d4f-2b1e7ed001a9"
      },
      "source": [
        "#Checking lengths\n",
        "print('x_train length ' + str(len(x_train)))\n",
        "print('x_test length ' + str(len(x_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train length 50000\n",
            "x_test length 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAhfX_5b0Tiv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c45590ec-4e3f-4075-e830-d5f844277306"
      },
      "source": [
        "#One hot encoding the target variables and standardising x inputs so they're\n",
        "#between 0 and 1\n",
        "y_input = tf.keras.utils.to_categorical(y_train)\n",
        "x_input = (x_train / 255.0)\n",
        "\n",
        "#Using test set as validation for simplicity\n",
        "y_valid = tf.keras.utils.to_categorical(y_test)\n",
        "x_valid = (x_test / 255.0)\n",
        "\n",
        "#Checking shape\n",
        "print('y_input shape ' + str(y_input.shape))\n",
        "print('x_input shape ' + str(x_input.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_input shape (50000, 20)\n",
            "x_input shape (50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFBqOM-x2cRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating descriptive labels for reference\n",
        "coarse_labels = [\n",
        "'aquatic mammals',\n",
        "'fish',\n",
        "'flowers',\n",
        "'food containers',\n",
        "'fruit and vegetables',\n",
        "'household electrical device',\n",
        "'household furniture',\n",
        "'insects',\n",
        "'large carnivores',\n",
        "'large man-made outdoor things',\n",
        "'large natural outdoor scenes',\n",
        "'large omnivores and herbivores',\n",
        "'medium-sized mammals',\n",
        "'non-insect invertebrates',\n",
        "'people',\n",
        "'reptiles',\n",
        "'small mammals',\n",
        "'trees',\n",
        "'vehicles 1',\n",
        "'vehicles 2',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yChJMpfTvmPf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a1daa9fc-8a21-43eb-8937-bcb485527e2e"
      },
      "source": [
        "#Example image coarse\n",
        "i=0\n",
        "label = y_train[i]\n",
        "image = x_train[i]\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.grid(False)\n",
        "plt.title((coarse_labels[int(label)]))\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c1wgdqG-ZFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLRf8aVTCm_V",
        "colab_type": "text"
      },
      "source": [
        "##Part 1 – Building an initial model to predict coarse labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tivtp5g4Iz4",
        "colab_type": "text"
      },
      "source": [
        "###Building initial model with adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egqjFPEzX04n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting up logging files\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#Creating layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same',\n",
        "  input_shape=( 32, 32, 3)))\n",
        "\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same'))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=20,activation=tf.nn.softmax))\n",
        "\n",
        "#Compiling model using an Adam optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "#Recording model checkpoints\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "#Logging to tensorboard\n",
        "tb_log = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "#Creating early stopping where validation loss does not improve\n",
        "#early_loss = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "#Save best model weights based on validation accuracy\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "callbacks = [tb_log,\n",
        "             #early_loss,\n",
        "             mcp_save]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W1p_mKbXG_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "90fdcb3b-bbf9-43a1-f667-c80c876c7780"
      },
      "source": [
        "#Fitting model\n",
        "model.fit(x_input, y_input, epochs=100,\n",
        "  batch_size=32,\n",
        "  callbacks=callbacks,\n",
        "  validation_data=(x_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 311/1563 [====>.........................] - ETA: 5s - loss: 2.5842 - accuracy: 0.2092"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-3d5d71cde100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   validation_data=(x_valid, y_valid))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyTwLP4wyvmJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8fbebe6-98f9-4671-d100-23911b864b4a"
      },
      "source": [
        "#Returning best weights\n",
        "model.load_weights(filepath = '.mdl_wts.hdf5')\n",
        "\n",
        "#Recording test accuracy\n",
        "predictions = model.predict(x_valid)\n",
        "y_pred = np.argmax(predictions,axis=-1)\n",
        "print('test accuracy: ', np.sum(y_pred==y_test[:,0])/len(y_test))\n",
        "## test accuracy: 0.4801"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy:  0.4851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR4Ethyh2wcw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24cae4f3-5a41-439e-f6e7-abb4e311fd6d"
      },
      "source": [
        "#Examining loss on TensorBoard\n",
        "%tensorboard --logdir logs/scalars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuYUm0NqQNHM",
        "colab_type": "text"
      },
      "source": [
        "###Building model with stochastic gradient descent optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e-puww8QL5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting up logging files\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#Creating layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same',\n",
        "  input_shape=( 32, 32, 3)))\n",
        "\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same'))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=20,activation=tf.nn.softmax))\n",
        "\n",
        "#Compiling model using a SGD optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(0.001),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "#Recording model checkpoints\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "#Logging to tensorboard\n",
        "tb_log = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "#Creating early stopping where validation loss does not improve\n",
        "#early_loss = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "#Save best model weights based on validation accuracy\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "callbacks = [tb_log,\n",
        "             #early_loss,\n",
        "             mcp_save]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9bANZ9ORMar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd61d0e0-b88a-4f86-d312-20687df510ae"
      },
      "source": [
        "#Fitting model\n",
        "model.fit(x_input, y_input, epochs=100,\n",
        "  batch_size=32,\n",
        "  callbacks=callbacks,\n",
        "  validation_data=(x_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.9209 - accuracy: 0.1094 - val_loss: 2.8166 - val_accuracy: 0.1430\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.7114 - accuracy: 0.1687 - val_loss: 2.6512 - val_accuracy: 0.1832\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.6000 - accuracy: 0.2065 - val_loss: 2.5740 - val_accuracy: 0.2156\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.5382 - accuracy: 0.2256 - val_loss: 2.5291 - val_accuracy: 0.2251\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.4903 - accuracy: 0.2391 - val_loss: 2.4940 - val_accuracy: 0.2324\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.4482 - accuracy: 0.2525 - val_loss: 2.4480 - val_accuracy: 0.2502\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.4129 - accuracy: 0.2617 - val_loss: 2.4220 - val_accuracy: 0.2598\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3802 - accuracy: 0.2715 - val_loss: 2.4039 - val_accuracy: 0.2651\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3517 - accuracy: 0.2797 - val_loss: 2.3524 - val_accuracy: 0.2789\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3231 - accuracy: 0.2911 - val_loss: 2.3502 - val_accuracy: 0.2819\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.2967 - accuracy: 0.2976 - val_loss: 2.3040 - val_accuracy: 0.2955\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.2685 - accuracy: 0.3059 - val_loss: 2.2922 - val_accuracy: 0.2950\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.2404 - accuracy: 0.3151 - val_loss: 2.2895 - val_accuracy: 0.2928\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.2138 - accuracy: 0.3226 - val_loss: 2.2425 - val_accuracy: 0.3128\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.1874 - accuracy: 0.3319 - val_loss: 2.2254 - val_accuracy: 0.3183\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.1633 - accuracy: 0.3384 - val_loss: 2.2039 - val_accuracy: 0.3212\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.1382 - accuracy: 0.3449 - val_loss: 2.1740 - val_accuracy: 0.3371\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.1157 - accuracy: 0.3535 - val_loss: 2.1555 - val_accuracy: 0.3364\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.0948 - accuracy: 0.3596 - val_loss: 2.1291 - val_accuracy: 0.3479\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.0733 - accuracy: 0.3670 - val_loss: 2.1158 - val_accuracy: 0.3463\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.0535 - accuracy: 0.3717 - val_loss: 2.1015 - val_accuracy: 0.3487\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.0352 - accuracy: 0.3771 - val_loss: 2.1007 - val_accuracy: 0.3556\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.0164 - accuracy: 0.3841 - val_loss: 2.0851 - val_accuracy: 0.3560\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9991 - accuracy: 0.3890 - val_loss: 2.0899 - val_accuracy: 0.3555\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9794 - accuracy: 0.3954 - val_loss: 2.0720 - val_accuracy: 0.3659\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9628 - accuracy: 0.3990 - val_loss: 2.0502 - val_accuracy: 0.3689\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9473 - accuracy: 0.4041 - val_loss: 2.0281 - val_accuracy: 0.3782\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9300 - accuracy: 0.4098 - val_loss: 2.0357 - val_accuracy: 0.3755\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9139 - accuracy: 0.4145 - val_loss: 2.0074 - val_accuracy: 0.3873\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8972 - accuracy: 0.4196 - val_loss: 2.0027 - val_accuracy: 0.3850\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8810 - accuracy: 0.4247 - val_loss: 2.0024 - val_accuracy: 0.3828\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8648 - accuracy: 0.4278 - val_loss: 2.0071 - val_accuracy: 0.3851\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8472 - accuracy: 0.4338 - val_loss: 1.9563 - val_accuracy: 0.4002\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8337 - accuracy: 0.4389 - val_loss: 1.9597 - val_accuracy: 0.3991\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8190 - accuracy: 0.4418 - val_loss: 1.9612 - val_accuracy: 0.4003\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8042 - accuracy: 0.4464 - val_loss: 1.9294 - val_accuracy: 0.4078\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7890 - accuracy: 0.4501 - val_loss: 1.9356 - val_accuracy: 0.4035\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7734 - accuracy: 0.4554 - val_loss: 1.9216 - val_accuracy: 0.4115\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7583 - accuracy: 0.4620 - val_loss: 1.9499 - val_accuracy: 0.4024\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7466 - accuracy: 0.4650 - val_loss: 1.9047 - val_accuracy: 0.4179\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7312 - accuracy: 0.4687 - val_loss: 1.8942 - val_accuracy: 0.4220\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7186 - accuracy: 0.4742 - val_loss: 1.9133 - val_accuracy: 0.4151\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7043 - accuracy: 0.4765 - val_loss: 1.8798 - val_accuracy: 0.4252\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6912 - accuracy: 0.4778 - val_loss: 1.8941 - val_accuracy: 0.4248\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6777 - accuracy: 0.4826 - val_loss: 1.8708 - val_accuracy: 0.4303\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6630 - accuracy: 0.4876 - val_loss: 1.8937 - val_accuracy: 0.4194\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6498 - accuracy: 0.4915 - val_loss: 1.9390 - val_accuracy: 0.4134\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6356 - accuracy: 0.4977 - val_loss: 1.8468 - val_accuracy: 0.4381\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6242 - accuracy: 0.5001 - val_loss: 1.8780 - val_accuracy: 0.4381\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6100 - accuracy: 0.5039 - val_loss: 1.8506 - val_accuracy: 0.4415\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5959 - accuracy: 0.5101 - val_loss: 1.8637 - val_accuracy: 0.4398\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5833 - accuracy: 0.5127 - val_loss: 1.8541 - val_accuracy: 0.4373\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5702 - accuracy: 0.5154 - val_loss: 1.8720 - val_accuracy: 0.4283\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5577 - accuracy: 0.5208 - val_loss: 1.8458 - val_accuracy: 0.4393\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5442 - accuracy: 0.5242 - val_loss: 1.8591 - val_accuracy: 0.4345\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5337 - accuracy: 0.5270 - val_loss: 1.8375 - val_accuracy: 0.4407\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5203 - accuracy: 0.5323 - val_loss: 1.8238 - val_accuracy: 0.4473\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5064 - accuracy: 0.5357 - val_loss: 1.8087 - val_accuracy: 0.4553\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4952 - accuracy: 0.5357 - val_loss: 1.8235 - val_accuracy: 0.4490\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4812 - accuracy: 0.5441 - val_loss: 1.8139 - val_accuracy: 0.4509\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4687 - accuracy: 0.5456 - val_loss: 1.8494 - val_accuracy: 0.4491\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4557 - accuracy: 0.5503 - val_loss: 1.8162 - val_accuracy: 0.4473\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4424 - accuracy: 0.5546 - val_loss: 1.8503 - val_accuracy: 0.4435\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4306 - accuracy: 0.5593 - val_loss: 1.8777 - val_accuracy: 0.4284\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4165 - accuracy: 0.5623 - val_loss: 1.8414 - val_accuracy: 0.4446\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4037 - accuracy: 0.5686 - val_loss: 1.8593 - val_accuracy: 0.4435\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3927 - accuracy: 0.5702 - val_loss: 1.8195 - val_accuracy: 0.4561\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3781 - accuracy: 0.5741 - val_loss: 1.8007 - val_accuracy: 0.4603\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3653 - accuracy: 0.5770 - val_loss: 1.8333 - val_accuracy: 0.4537\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3518 - accuracy: 0.5825 - val_loss: 1.8507 - val_accuracy: 0.4448\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3396 - accuracy: 0.5856 - val_loss: 1.8332 - val_accuracy: 0.4549\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3261 - accuracy: 0.5916 - val_loss: 1.8333 - val_accuracy: 0.4561\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3124 - accuracy: 0.5937 - val_loss: 1.8131 - val_accuracy: 0.4610\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2985 - accuracy: 0.6003 - val_loss: 1.8324 - val_accuracy: 0.4581\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2852 - accuracy: 0.6038 - val_loss: 1.8265 - val_accuracy: 0.4570\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2723 - accuracy: 0.6086 - val_loss: 1.9072 - val_accuracy: 0.4397\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2581 - accuracy: 0.6115 - val_loss: 1.8719 - val_accuracy: 0.4515\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2461 - accuracy: 0.6158 - val_loss: 1.8879 - val_accuracy: 0.4525\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2324 - accuracy: 0.6197 - val_loss: 1.8155 - val_accuracy: 0.4674\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2208 - accuracy: 0.6231 - val_loss: 1.8388 - val_accuracy: 0.4567\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2034 - accuracy: 0.6278 - val_loss: 1.8277 - val_accuracy: 0.4655\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1936 - accuracy: 0.6323 - val_loss: 1.8504 - val_accuracy: 0.4586\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1785 - accuracy: 0.6366 - val_loss: 1.8303 - val_accuracy: 0.4566\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1632 - accuracy: 0.6405 - val_loss: 1.8892 - val_accuracy: 0.4583\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1511 - accuracy: 0.6457 - val_loss: 1.8228 - val_accuracy: 0.4653\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1387 - accuracy: 0.6484 - val_loss: 1.8493 - val_accuracy: 0.4619\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1226 - accuracy: 0.6528 - val_loss: 1.8899 - val_accuracy: 0.4615\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1101 - accuracy: 0.6585 - val_loss: 1.8456 - val_accuracy: 0.4680\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0946 - accuracy: 0.6635 - val_loss: 1.8975 - val_accuracy: 0.4605\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0797 - accuracy: 0.6675 - val_loss: 1.8737 - val_accuracy: 0.4616\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0663 - accuracy: 0.6701 - val_loss: 1.9460 - val_accuracy: 0.4424\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0513 - accuracy: 0.6765 - val_loss: 1.9091 - val_accuracy: 0.4620\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0378 - accuracy: 0.6800 - val_loss: 1.8867 - val_accuracy: 0.4587\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0227 - accuracy: 0.6841 - val_loss: 1.9180 - val_accuracy: 0.4513\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0100 - accuracy: 0.6867 - val_loss: 1.9113 - val_accuracy: 0.4574\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9949 - accuracy: 0.6926 - val_loss: 1.9064 - val_accuracy: 0.4645\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9794 - accuracy: 0.6988 - val_loss: 1.8991 - val_accuracy: 0.4667\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9664 - accuracy: 0.7035 - val_loss: 1.8938 - val_accuracy: 0.4692\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9519 - accuracy: 0.7087 - val_loss: 2.0132 - val_accuracy: 0.4543\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9374 - accuracy: 0.7134 - val_loss: 1.9781 - val_accuracy: 0.4509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9980556160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_6gVrPiQWWz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9054b456-77b3-4233-b960-d15474a7488d"
      },
      "source": [
        "#Returning best weights\n",
        "model.load_weights(filepath = '.mdl_wts.hdf5')\n",
        "\n",
        "#Recording test accuracy\n",
        "predictions = model.predict(x_valid)\n",
        "y_pred = np.argmax(predictions,axis=-1)\n",
        "print('test accuracy: ', np.sum(y_pred==y_test[:,0])/len(y_test))\n",
        "## test accuracy: 0.4692"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy:  0.4692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ivdfT1vQt-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Examining loss on TensorBoard\n",
        "%tensorboard --logdir logs/scalars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vvz1ed8CEyE",
        "colab_type": "text"
      },
      "source": [
        "###Building 16 batch model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZZpGZmcCEPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting up logging files\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#Creating layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same',\n",
        "  input_shape=( 32, 32, 3)))\n",
        "\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same'))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=20,activation=tf.nn.softmax))\n",
        "\n",
        "#Compiling model using an Adam optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "#Recording model checkpoints\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "#Logging to tensorboard\n",
        "tb_log = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "#Creating early stopping where validation loss does not improve\n",
        "#early_loss = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "#Save best model weights based on validation accuracy\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "callbacks = [tb_log,\n",
        "             #early_loss,\n",
        "             mcp_save]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bUMyX3rCPMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "a30180f5-8cd1-4369-ad06-e1782a5fe318"
      },
      "source": [
        "#Fitting model\n",
        "model.fit(x_input, y_input, epochs=20,\n",
        "  batch_size=16,\n",
        "  callbacks=callbacks,\n",
        "  validation_data=(x_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 2.2541 - accuracy: 0.3052 - val_loss: 2.0142 - val_accuracy: 0.3781\n",
            "Epoch 2/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 1.8180 - accuracy: 0.4355 - val_loss: 1.7878 - val_accuracy: 0.4465\n",
            "Epoch 3/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 1.5584 - accuracy: 0.5141 - val_loss: 1.7344 - val_accuracy: 0.4693\n",
            "Epoch 4/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 1.3326 - accuracy: 0.5808 - val_loss: 1.7745 - val_accuracy: 0.4790\n",
            "Epoch 5/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 1.1141 - accuracy: 0.6459 - val_loss: 1.9183 - val_accuracy: 0.4672\n",
            "Epoch 6/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 0.8979 - accuracy: 0.7140 - val_loss: 2.1897 - val_accuracy: 0.4435\n",
            "Epoch 7/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 0.7005 - accuracy: 0.7755 - val_loss: 2.4559 - val_accuracy: 0.4516\n",
            "Epoch 8/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 0.5304 - accuracy: 0.8272 - val_loss: 2.8219 - val_accuracy: 0.4409\n",
            "Epoch 9/20\n",
            "3125/3125 [==============================] - 15s 5ms/step - loss: 0.4114 - accuracy: 0.8659 - val_loss: 3.2529 - val_accuracy: 0.4331\n",
            "Epoch 10/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 0.3215 - accuracy: 0.8942 - val_loss: 3.5276 - val_accuracy: 0.4278\n",
            "Epoch 11/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 0.2590 - accuracy: 0.9151 - val_loss: 3.9943 - val_accuracy: 0.4275\n",
            "Epoch 12/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 0.2234 - accuracy: 0.9257 - val_loss: 4.4629 - val_accuracy: 0.4208\n",
            "Epoch 13/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 0.1994 - accuracy: 0.9343 - val_loss: 4.8341 - val_accuracy: 0.4212\n",
            "Epoch 14/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 0.1765 - accuracy: 0.9419 - val_loss: 5.3007 - val_accuracy: 0.4218\n",
            "Epoch 15/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 0.1676 - accuracy: 0.9446 - val_loss: 5.1784 - val_accuracy: 0.4150\n",
            "Epoch 16/20\n",
            "3125/3125 [==============================] - 14s 5ms/step - loss: 0.1470 - accuracy: 0.9532 - val_loss: 5.4790 - val_accuracy: 0.4123\n",
            "Epoch 17/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 0.1399 - accuracy: 0.9557 - val_loss: 6.0189 - val_accuracy: 0.4121\n",
            "Epoch 18/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 0.1393 - accuracy: 0.9560 - val_loss: 5.9850 - val_accuracy: 0.4106\n",
            "Epoch 19/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 0.1366 - accuracy: 0.9572 - val_loss: 6.3734 - val_accuracy: 0.4124\n",
            "Epoch 20/20\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 0.1258 - accuracy: 0.9606 - val_loss: 6.5906 - val_accuracy: 0.4031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f99fe09f898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCBudWDeDBok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa9c8b93-4540-47c9-9f2f-c547e53a0d5d"
      },
      "source": [
        "#Returning best weights\n",
        "model.load_weights(filepath = '.mdl_wts.hdf5')\n",
        "\n",
        "#Recording test accuracy\n",
        "predictions = model.predict(x_valid)\n",
        "y_pred = np.argmax(predictions,axis=-1)\n",
        "print('test accuracy: ', np.sum(y_pred==y_test[:,0])/len(y_test))\n",
        "## test accuracy: 0.479"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy:  0.479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-dpUPqCFRdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Examining loss on TensorBoard\n",
        "%tensorboard --logdir logs/scalars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBkHoNoQ_NI3",
        "colab_type": "text"
      },
      "source": [
        "###Building 64 batch model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw1oG4NB_TCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting up logging files\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#Creating layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same',\n",
        "  input_shape=( 32, 32, 3)))\n",
        "\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same'))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=20,activation=tf.nn.softmax))\n",
        "\n",
        "#Compiling model using an Adam optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "#Recording model checkpoints\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "#Logging to tensorboard\n",
        "tb_log = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "#Creating early stopping where validation loss does not improve\n",
        "#early_loss = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "#Save best model weights based on validation accuracy\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "callbacks = [tb_log,\n",
        "             #early_loss,\n",
        "             mcp_save]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAfLEI6B_Mqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "db8c38e8-35db-47b9-bd9a-8178f1bd68af"
      },
      "source": [
        "#Fitting model\n",
        "model.fit(x_input, y_input, epochs=20,\n",
        "  batch_size=64,\n",
        "  callbacks=callbacks,\n",
        "  validation_data=(x_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 2.2771 - accuracy: 0.3005 - val_loss: 2.0184 - val_accuracy: 0.3797\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.8194 - accuracy: 0.4385 - val_loss: 1.8106 - val_accuracy: 0.4408\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.5895 - accuracy: 0.5063 - val_loss: 1.8412 - val_accuracy: 0.4449\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.3961 - accuracy: 0.5644 - val_loss: 1.7145 - val_accuracy: 0.4765\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.2284 - accuracy: 0.6136 - val_loss: 1.6701 - val_accuracy: 0.4963\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.0473 - accuracy: 0.6689 - val_loss: 1.7936 - val_accuracy: 0.4862\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.8753 - accuracy: 0.7215 - val_loss: 1.9004 - val_accuracy: 0.4888\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.7074 - accuracy: 0.7756 - val_loss: 2.0165 - val_accuracy: 0.4862\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.5580 - accuracy: 0.8238 - val_loss: 2.2485 - val_accuracy: 0.4855\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.4323 - accuracy: 0.8636 - val_loss: 2.5118 - val_accuracy: 0.4697\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3247 - accuracy: 0.8977 - val_loss: 2.7480 - val_accuracy: 0.4643\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.2440 - accuracy: 0.9232 - val_loss: 3.1371 - val_accuracy: 0.4628\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.2039 - accuracy: 0.9362 - val_loss: 3.4159 - val_accuracy: 0.4498\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.1669 - accuracy: 0.9460 - val_loss: 3.7962 - val_accuracy: 0.4549\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.1347 - accuracy: 0.9585 - val_loss: 3.9123 - val_accuracy: 0.4573\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.1327 - accuracy: 0.9571 - val_loss: 4.1534 - val_accuracy: 0.4453\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.1170 - accuracy: 0.9621 - val_loss: 4.0745 - val_accuracy: 0.4467\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.1211 - accuracy: 0.9609 - val_loss: 4.3523 - val_accuracy: 0.4476\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0933 - accuracy: 0.9703 - val_loss: 4.6785 - val_accuracy: 0.4510\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0848 - accuracy: 0.9729 - val_loss: 4.8869 - val_accuracy: 0.4484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f99d29729e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LfZPlG8_QHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdc464a7-bd52-481f-c342-ecdeaee8dfe2"
      },
      "source": [
        "#Returning best weights\n",
        "model.load_weights(filepath = '.mdl_wts.hdf5')\n",
        "\n",
        "#Recording test accuracy\n",
        "predictions = model.predict(x_valid)\n",
        "y_pred = np.argmax(predictions,axis=-1)\n",
        "print('test accuracy: ', np.sum(y_pred==y_test[:,0])/len(y_test))\n",
        "## test accuracy: 0.4963"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy:  0.4963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8C6s5bO_aCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Examining loss on TensorBoard\n",
        "%tensorboard --logdir logs/scalars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Em1duioJXpB",
        "colab_type": "text"
      },
      "source": [
        "###Building a smaller learning rate model (1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8e0xnEsJhF5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "543f83d9-3575-473d-fe5f-29b82ecb835e"
      },
      "source": [
        "#Setting up logging files\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#Creating layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same',\n",
        "  input_shape=( 32, 32, 3)))\n",
        "\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same'))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=20,activation=tf.nn.softmax))\n",
        "\n",
        "#Compiling model using an Adam optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "#Recording model checkpoints\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "#Logging to tensorboard\n",
        "tb_log = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "#Creating early stopping where validation loss does not improve\n",
        "#early_loss = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "#Save best model weights based on validation accuracy\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "callbacks = [tb_log,\n",
        "             #early_loss,\n",
        "             mcp_save]\n",
        "\n",
        "#Fitting model\n",
        "model.fit(x_input, y_input, epochs=100,\n",
        "  batch_size=64,\n",
        "  callbacks=callbacks,\n",
        "  validation_data=(x_valid, y_valid))\n",
        "\n",
        "#Returning best weights\n",
        "model.load_weights(filepath = '.mdl_wts.hdf5')\n",
        "\n",
        "#Recording test accuracy\n",
        "predictions = model.predict(x_valid)\n",
        "y_pred = np.argmax(predictions,axis=-1)\n",
        "print('test accuracy: ', np.sum(y_pred==y_test[:,0])/len(y_test))\n",
        "## test accuracy: 0.4963\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 2.5121 - accuracy: 0.2356 - val_loss: 2.3127 - val_accuracy: 0.2945\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 2.2011 - accuracy: 0.3311 - val_loss: 2.1636 - val_accuracy: 0.3365\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 2.0760 - accuracy: 0.3677 - val_loss: 2.1281 - val_accuracy: 0.3423\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.9865 - accuracy: 0.3941 - val_loss: 2.0232 - val_accuracy: 0.3818\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.9155 - accuracy: 0.4155 - val_loss: 1.9807 - val_accuracy: 0.3941\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.8535 - accuracy: 0.4338 - val_loss: 1.9313 - val_accuracy: 0.4112\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.8012 - accuracy: 0.4500 - val_loss: 1.9081 - val_accuracy: 0.4198\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.7556 - accuracy: 0.4633 - val_loss: 1.8574 - val_accuracy: 0.4367\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.7133 - accuracy: 0.4759 - val_loss: 1.8533 - val_accuracy: 0.4347\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.6706 - accuracy: 0.4874 - val_loss: 1.8173 - val_accuracy: 0.4451\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.6341 - accuracy: 0.4985 - val_loss: 1.7885 - val_accuracy: 0.4571\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.5998 - accuracy: 0.5098 - val_loss: 1.7872 - val_accuracy: 0.4569\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.5642 - accuracy: 0.5222 - val_loss: 1.7746 - val_accuracy: 0.4636\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.5307 - accuracy: 0.5303 - val_loss: 1.7578 - val_accuracy: 0.4665\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.4997 - accuracy: 0.5389 - val_loss: 1.7795 - val_accuracy: 0.4603\n",
            "Epoch 16/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.4674 - accuracy: 0.5511 - val_loss: 1.7485 - val_accuracy: 0.4726\n",
            "Epoch 17/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.4420 - accuracy: 0.5566 - val_loss: 1.7168 - val_accuracy: 0.4815\n",
            "Epoch 18/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.4082 - accuracy: 0.5670 - val_loss: 1.7156 - val_accuracy: 0.4829\n",
            "Epoch 19/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.3809 - accuracy: 0.5746 - val_loss: 1.7237 - val_accuracy: 0.4765\n",
            "Epoch 20/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.3513 - accuracy: 0.5852 - val_loss: 1.7287 - val_accuracy: 0.4812\n",
            "Epoch 21/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.3260 - accuracy: 0.5929 - val_loss: 1.6870 - val_accuracy: 0.4922\n",
            "Epoch 22/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.2968 - accuracy: 0.6015 - val_loss: 1.6870 - val_accuracy: 0.4978\n",
            "Epoch 23/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.2707 - accuracy: 0.6091 - val_loss: 1.8113 - val_accuracy: 0.4679\n",
            "Epoch 24/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.2447 - accuracy: 0.6169 - val_loss: 1.6941 - val_accuracy: 0.4953\n",
            "Epoch 25/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.2195 - accuracy: 0.6263 - val_loss: 1.7188 - val_accuracy: 0.4936\n",
            "Epoch 26/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1922 - accuracy: 0.6321 - val_loss: 1.6774 - val_accuracy: 0.4984\n",
            "Epoch 27/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1661 - accuracy: 0.6419 - val_loss: 1.6929 - val_accuracy: 0.4943\n",
            "Epoch 28/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.1426 - accuracy: 0.6478 - val_loss: 1.6961 - val_accuracy: 0.4944\n",
            "Epoch 29/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1207 - accuracy: 0.6554 - val_loss: 1.6842 - val_accuracy: 0.5008\n",
            "Epoch 30/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.0949 - accuracy: 0.6641 - val_loss: 1.6871 - val_accuracy: 0.5009\n",
            "Epoch 31/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.0701 - accuracy: 0.6714 - val_loss: 1.7341 - val_accuracy: 0.4929\n",
            "Epoch 32/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.0451 - accuracy: 0.6785 - val_loss: 1.7106 - val_accuracy: 0.4968\n",
            "Epoch 33/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.0203 - accuracy: 0.6879 - val_loss: 1.7186 - val_accuracy: 0.4975\n",
            "Epoch 34/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.9970 - accuracy: 0.6954 - val_loss: 1.7143 - val_accuracy: 0.5023\n",
            "Epoch 35/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.9732 - accuracy: 0.7023 - val_loss: 1.7466 - val_accuracy: 0.4939\n",
            "Epoch 36/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.9501 - accuracy: 0.7100 - val_loss: 1.7499 - val_accuracy: 0.4953\n",
            "Epoch 37/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.9276 - accuracy: 0.7168 - val_loss: 1.7328 - val_accuracy: 0.4975\n",
            "Epoch 38/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.8994 - accuracy: 0.7276 - val_loss: 1.7533 - val_accuracy: 0.5018\n",
            "Epoch 39/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.8784 - accuracy: 0.7319 - val_loss: 1.7776 - val_accuracy: 0.4975\n",
            "Epoch 40/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.8547 - accuracy: 0.7409 - val_loss: 1.7871 - val_accuracy: 0.4970\n",
            "Epoch 41/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.8298 - accuracy: 0.7497 - val_loss: 1.7868 - val_accuracy: 0.4976\n",
            "Epoch 42/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.8087 - accuracy: 0.7550 - val_loss: 1.8273 - val_accuracy: 0.4867\n",
            "Epoch 43/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.7872 - accuracy: 0.7632 - val_loss: 1.8223 - val_accuracy: 0.4966\n",
            "Epoch 44/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.7626 - accuracy: 0.7718 - val_loss: 1.8413 - val_accuracy: 0.4933\n",
            "Epoch 45/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.7390 - accuracy: 0.7783 - val_loss: 1.8827 - val_accuracy: 0.4911\n",
            "Epoch 46/100\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.7181 - accuracy: 0.7868 - val_loss: 1.8935 - val_accuracy: 0.4890\n",
            "Epoch 47/100\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.6982 - accuracy: 0.7920 - val_loss: 1.8893 - val_accuracy: 0.4904\n",
            "Epoch 48/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.6718 - accuracy: 0.8023 - val_loss: 1.9113 - val_accuracy: 0.4913\n",
            "Epoch 49/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.6495 - accuracy: 0.8087 - val_loss: 1.9183 - val_accuracy: 0.4919\n",
            "Epoch 50/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.6296 - accuracy: 0.8164 - val_loss: 1.9579 - val_accuracy: 0.4869\n",
            "Epoch 51/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.6078 - accuracy: 0.8229 - val_loss: 2.0149 - val_accuracy: 0.4808\n",
            "Epoch 52/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.5868 - accuracy: 0.8308 - val_loss: 2.0292 - val_accuracy: 0.4879\n",
            "Epoch 53/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.5639 - accuracy: 0.8387 - val_loss: 2.0923 - val_accuracy: 0.4799\n",
            "Epoch 54/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.5447 - accuracy: 0.8434 - val_loss: 2.0765 - val_accuracy: 0.4794\n",
            "Epoch 55/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.5236 - accuracy: 0.8516 - val_loss: 2.0552 - val_accuracy: 0.4875\n",
            "Epoch 56/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.5028 - accuracy: 0.8597 - val_loss: 2.1025 - val_accuracy: 0.4899\n",
            "Epoch 57/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.4825 - accuracy: 0.8650 - val_loss: 2.1528 - val_accuracy: 0.4825\n",
            "Epoch 58/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.4623 - accuracy: 0.8728 - val_loss: 2.1727 - val_accuracy: 0.4802\n",
            "Epoch 59/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.4417 - accuracy: 0.8790 - val_loss: 2.1970 - val_accuracy: 0.4815\n",
            "Epoch 60/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.4254 - accuracy: 0.8859 - val_loss: 2.2250 - val_accuracy: 0.4829\n",
            "Epoch 61/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.4104 - accuracy: 0.8892 - val_loss: 2.2553 - val_accuracy: 0.4742\n",
            "Epoch 62/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.3884 - accuracy: 0.8971 - val_loss: 2.2861 - val_accuracy: 0.4824\n",
            "Epoch 63/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.3681 - accuracy: 0.9045 - val_loss: 2.3391 - val_accuracy: 0.4785\n",
            "Epoch 64/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3520 - accuracy: 0.9114 - val_loss: 2.3816 - val_accuracy: 0.4811\n",
            "Epoch 65/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.3367 - accuracy: 0.9146 - val_loss: 2.4156 - val_accuracy: 0.4799\n",
            "Epoch 66/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3189 - accuracy: 0.9206 - val_loss: 2.4227 - val_accuracy: 0.4776\n",
            "Epoch 67/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.3042 - accuracy: 0.9246 - val_loss: 2.5359 - val_accuracy: 0.4719\n",
            "Epoch 68/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.2889 - accuracy: 0.9306 - val_loss: 2.5132 - val_accuracy: 0.4780\n",
            "Epoch 69/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.2703 - accuracy: 0.9364 - val_loss: 2.5691 - val_accuracy: 0.4711\n",
            "Epoch 70/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.2584 - accuracy: 0.9399 - val_loss: 2.5934 - val_accuracy: 0.4751\n",
            "Epoch 71/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.2399 - accuracy: 0.9459 - val_loss: 2.6452 - val_accuracy: 0.4702\n",
            "Epoch 72/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.2281 - accuracy: 0.9492 - val_loss: 2.7537 - val_accuracy: 0.4696\n",
            "Epoch 73/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.2169 - accuracy: 0.9531 - val_loss: 2.7196 - val_accuracy: 0.4731\n",
            "Epoch 74/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.2082 - accuracy: 0.9549 - val_loss: 2.7952 - val_accuracy: 0.4701\n",
            "Epoch 75/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.1919 - accuracy: 0.9600 - val_loss: 2.8115 - val_accuracy: 0.4666\n",
            "Epoch 76/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.1844 - accuracy: 0.9618 - val_loss: 2.8315 - val_accuracy: 0.4732\n",
            "Epoch 77/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.1694 - accuracy: 0.9657 - val_loss: 2.9353 - val_accuracy: 0.4631\n",
            "Epoch 78/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.1615 - accuracy: 0.9674 - val_loss: 2.9774 - val_accuracy: 0.4686\n",
            "Epoch 79/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.1533 - accuracy: 0.9699 - val_loss: 3.1093 - val_accuracy: 0.4601\n",
            "Epoch 80/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.1361 - accuracy: 0.9758 - val_loss: 3.0453 - val_accuracy: 0.4696\n",
            "Epoch 81/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.1329 - accuracy: 0.9757 - val_loss: 3.0957 - val_accuracy: 0.4708\n",
            "Epoch 82/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.1260 - accuracy: 0.9780 - val_loss: 3.1823 - val_accuracy: 0.4653\n",
            "Epoch 83/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.1144 - accuracy: 0.9808 - val_loss: 3.3288 - val_accuracy: 0.4579\n",
            "Epoch 84/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.1075 - accuracy: 0.9825 - val_loss: 3.2913 - val_accuracy: 0.4646\n",
            "Epoch 85/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.1008 - accuracy: 0.9836 - val_loss: 3.3318 - val_accuracy: 0.4667\n",
            "Epoch 86/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.1020 - accuracy: 0.9820 - val_loss: 3.4292 - val_accuracy: 0.4615\n",
            "Epoch 87/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0874 - accuracy: 0.9871 - val_loss: 3.4246 - val_accuracy: 0.4698\n",
            "Epoch 88/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0873 - accuracy: 0.9856 - val_loss: 3.4587 - val_accuracy: 0.4651\n",
            "Epoch 89/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0759 - accuracy: 0.9894 - val_loss: 3.5385 - val_accuracy: 0.4664\n",
            "Epoch 90/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0734 - accuracy: 0.9897 - val_loss: 3.6079 - val_accuracy: 0.4648\n",
            "Epoch 91/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0698 - accuracy: 0.9895 - val_loss: 3.7079 - val_accuracy: 0.4571\n",
            "Epoch 92/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0701 - accuracy: 0.9890 - val_loss: 3.7043 - val_accuracy: 0.4604\n",
            "Epoch 93/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0604 - accuracy: 0.9920 - val_loss: 3.7622 - val_accuracy: 0.4593\n",
            "Epoch 94/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0621 - accuracy: 0.9904 - val_loss: 3.7698 - val_accuracy: 0.4606\n",
            "Epoch 95/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0562 - accuracy: 0.9921 - val_loss: 3.8081 - val_accuracy: 0.4650\n",
            "Epoch 96/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0592 - accuracy: 0.9908 - val_loss: 3.8577 - val_accuracy: 0.4655\n",
            "Epoch 97/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0403 - accuracy: 0.9961 - val_loss: 3.8936 - val_accuracy: 0.4618\n",
            "Epoch 98/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0586 - accuracy: 0.9896 - val_loss: 3.9864 - val_accuracy: 0.4613\n",
            "Epoch 99/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.0398 - accuracy: 0.9955 - val_loss: 4.0815 - val_accuracy: 0.4588\n",
            "Epoch 100/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.0492 - accuracy: 0.9920 - val_loss: 4.0698 - val_accuracy: 0.4611\n",
            "test accuracy:  0.5023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "792Kxq6UKLZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Examining loss on TensorBoard\n",
        "%tensorboard --logdir logs/scalars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwghI0E1K4ci",
        "colab_type": "text"
      },
      "source": [
        "###Building a larger learning rate model (1e-2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hvh6gerKl_U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "93888a4d-0341-4540-f353-e020b47d5f6a"
      },
      "source": [
        "#Setting up logging files\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#Creating layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same',\n",
        "  input_shape=( 32, 32, 3)))\n",
        "\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same'))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))\n",
        "2\n",
        "model.add(tf.keras.layers.Dense(units=20,activation=tf.nn.softmax))\n",
        "\n",
        "#Compiling model using an Adam optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-2),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "#Recording model checkpoints\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "#Logging to tensorboard\n",
        "tb_log = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "#Creating early stopping where validation loss does not improve\n",
        "#early_loss = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "#Save best model weights based on validation accuracy\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "callbacks = [tb_log,\n",
        "             #early_loss,\n",
        "             mcp_save]\n",
        "\n",
        "#Fitting model\n",
        "model.fit(x_input, y_input, epochs=100,\n",
        "  batch_size=64,\n",
        "  callbacks=callbacks,\n",
        "  validation_data=(x_valid, y_valid))\n",
        "\n",
        "#Returning best weights\n",
        "model.load_weights(filepath = '.mdl_wts.hdf5')\n",
        "\n",
        "#Recording test accuracy\n",
        "predictions = model.predict(x_valid)\n",
        "y_pred = np.argmax(predictions,axis=-1)\n",
        "print('test accuracy: ', np.sum(y_pred==y_test[:,0])/len(y_test))\n",
        "## test accuracy: 0.4963\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 3.0319 - accuracy: 0.0512 - val_loss: 2.9967 - val_accuracy: 0.0500\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 2.9973 - accuracy: 0.0485 - val_loss: 2.9965 - val_accuracy: 0.0500\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 2.9972 - accuracy: 0.0508 - val_loss: 2.9969 - val_accuracy: 0.0500\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 2.9972 - accuracy: 0.0490 - val_loss: 2.9970 - val_accuracy: 0.0500\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 2.9973 - accuracy: 0.0496 - val_loss: 2.9968 - val_accuracy: 0.0500\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 2.9971 - accuracy: 0.0491 - val_loss: 2.9970 - val_accuracy: 0.0500\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 2.9975 - accuracy: 0.0500 - val_loss: 2.9969 - val_accuracy: 0.0500\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 2.9971 - accuracy: 0.0514 - val_loss: 2.9972 - val_accuracy: 0.0500\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 2.9973 - accuracy: 0.0485 - val_loss: 2.9966 - val_accuracy: 0.0500\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 2.9973 - accuracy: 0.0493 - val_loss: 2.9970 - val_accuracy: 0.0500\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 2.9971 - accuracy: 0.0492 - val_loss: 2.9970 - val_accuracy: 0.0500\n",
            "Epoch 12/100\n",
            "775/782 [============================>.] - ETA: 0s - loss: 2.9972 - accuracy: 0.0489"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-b59cab318221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   validation_data=(x_valid, y_valid))\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#Returning best weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    870\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    873\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1055\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func)\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m     \"\"\"\n\u001b[0;32m-> 1652\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m   def interleave(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[1;32m   4069\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4070\u001b[0m     self._map_func = StructuredFunctionWrapper(\n\u001b[0;32m-> 4071\u001b[0;31m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0m\u001b[1;32m   4072\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4073\u001b[0m       raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3219\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \"\"\"\n\u001b[1;32m   2531\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2532\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2533\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0;31m# TensorArrays and `None`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m       func_outputs = nest.map_structure(convert, func_outputs,\n\u001b[0;32m--> 986\u001b[0;31m                                         expand_composites=True)\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0mcheck_mutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_args_before\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m    617\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       expand_composites=expand_composites)\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m   \"\"\"\n\u001b[0;32m--> 552\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    514\u001b[0m           \u001b[0;34m\"flat_sequence had %d elements.  Structure: %s, flat_sequence: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m           (len(flat_structure), len(flat_sequence), structure, flat_sequence))\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msequence_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_sequence_like\u001b[0;34m(instance, args)\u001b[0m\n\u001b[1;32m    180\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_sequence_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_wrapt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectProxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0;31m# For object proxies, first create the underlying type and then re-wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# in the proxy type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLQfQ6FRKpn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Examining loss on TensorBoard\n",
        "%tensorboard --logdir logs/scalars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RllyshVIF11p",
        "colab_type": "text"
      },
      "source": [
        "##Part 2 - Optimising the model architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfZm4xmSzddB",
        "colab_type": "text"
      },
      "source": [
        "###Adding in drop out layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0wuIVOqzCLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "e04888e4-01b6-45c2-f0be-7622427499ce"
      },
      "source": [
        "#Setting up logging files\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#Creating layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same',\n",
        "  input_shape=( 32, 32, 3)))\n",
        "\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same'))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=20,activation=tf.nn.softmax))\n",
        "\n",
        "#Compiling model using an Adam optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "#Recording model checkpoints\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "#Logging to tensorboard\n",
        "tb_log = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "#Creating early stopping where validation loss does not improve\n",
        "#early_loss = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "#Save best model weights based on validation accuracy\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "callbacks = [tb_log,\n",
        "             #early_loss,\n",
        "             mcp_save]\n",
        "\n",
        "#Fitting model\n",
        "model.fit(x_input, y_input, epochs=100,\n",
        "  batch_size=64,\n",
        "  callbacks=callbacks,\n",
        "  validation_data=(x_valid, y_valid))\n",
        "\n",
        "#Returning best weights\n",
        "model.load_weights(filepath = '.mdl_wts.hdf5')\n",
        "\n",
        "#Recording test accuracy\n",
        "predictions = model.predict(x_valid)\n",
        "y_pred = np.argmax(predictions,axis=-1)\n",
        "print('test accuracy: ', np.sum(y_pred==y_test[:,0])/len(y_test))\n",
        "## test accuracy: 0.5132"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  2/782 [..............................] - ETA: 5:54 - loss: 3.1386 - accuracy: 0.0625WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.452918). Check your callbacks.\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.5985 - accuracy: 0.1966 - val_loss: 2.2589 - val_accuracy: 0.3192\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 2.3186 - accuracy: 0.2856 - val_loss: 2.0883 - val_accuracy: 0.3711\n",
            "Epoch 3/100\n",
            "291/782 [==========>...................] - ETA: 2s - loss: 2.2173 - accuracy: 0.3170"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-87da973d21b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m   validation_data=(x_valid, y_valid))\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m#Returning best weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ3TOhAa2BFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Examining loss on TensorBoard\n",
        "%tensorboard --logdir logs/scalars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj7OBifY5Xea",
        "colab_type": "text"
      },
      "source": [
        "###Adding in convolutional layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0O5toXA2yXf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7bf2074-e0b5-4c2d-b92b-f6486cea3536"
      },
      "source": [
        "#Setting up logging files\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#Creating layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same',\n",
        "  input_shape=( 32, 32, 3)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same',\n",
        "  input_shape=( 32, 32, 3)))\n",
        "\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same'))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same'))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=20,activation=tf.nn.softmax))\n",
        "\n",
        "#Compiling model using an Adam optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "#Recording model checkpoints\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "#Logging to tensorboard\n",
        "tb_log = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "#Creating early stopping where validation loss does not improve\n",
        "#early_loss = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "#Save best model weights based on validation accuracy\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "callbacks = [tb_log,\n",
        "             #early_loss,\n",
        "             mcp_save]\n",
        "\n",
        "#Fitting model\n",
        "model.fit(x_input, y_input, epochs=100,\n",
        "  batch_size=64,\n",
        "  callbacks=callbacks,\n",
        "  validation_data=(x_valid, y_valid))\n",
        "\n",
        "#Returning best weights\n",
        "model.load_weights(filepath = '.mdl_wts.hdf5')\n",
        "\n",
        "#Recording test accuracy\n",
        "predictions = model.predict(x_valid)\n",
        "y_pred = np.argmax(predictions,axis=-1)\n",
        "print('test accuracy: ', np.sum(y_pred==y_test[:,0])/len(y_test))\n",
        "## test accuracy: 0.5515"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 2.5993 - accuracy: 0.1954 - val_loss: 2.2612 - val_accuracy: 0.2963\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 2.2868 - accuracy: 0.2916 - val_loss: 2.0199 - val_accuracy: 0.3814\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 2.1138 - accuracy: 0.3446 - val_loss: 1.8833 - val_accuracy: 0.4146\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.9889 - accuracy: 0.3823 - val_loss: 1.7880 - val_accuracy: 0.4435\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.8966 - accuracy: 0.4054 - val_loss: 1.7386 - val_accuracy: 0.4555\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.8083 - accuracy: 0.4325 - val_loss: 1.6640 - val_accuracy: 0.4825\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.7392 - accuracy: 0.4507 - val_loss: 1.6369 - val_accuracy: 0.4884\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.6727 - accuracy: 0.4673 - val_loss: 1.6191 - val_accuracy: 0.4975\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.6215 - accuracy: 0.4813 - val_loss: 1.5919 - val_accuracy: 0.5054\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.5675 - accuracy: 0.4961 - val_loss: 1.5732 - val_accuracy: 0.5100\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.5136 - accuracy: 0.5114 - val_loss: 1.5621 - val_accuracy: 0.5130\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.4848 - accuracy: 0.5208 - val_loss: 1.5357 - val_accuracy: 0.5182\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.4339 - accuracy: 0.5338 - val_loss: 1.5177 - val_accuracy: 0.5333\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.3873 - accuracy: 0.5488 - val_loss: 1.6114 - val_accuracy: 0.5141\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.3563 - accuracy: 0.5568 - val_loss: 1.5809 - val_accuracy: 0.5196\n",
            "Epoch 16/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3245 - accuracy: 0.5637 - val_loss: 1.5189 - val_accuracy: 0.5400\n",
            "Epoch 17/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.2957 - accuracy: 0.5731 - val_loss: 1.5202 - val_accuracy: 0.5367\n",
            "Epoch 18/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.2705 - accuracy: 0.5809 - val_loss: 1.5351 - val_accuracy: 0.5387\n",
            "Epoch 19/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.2407 - accuracy: 0.5888 - val_loss: 1.5788 - val_accuracy: 0.5293\n",
            "Epoch 20/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.2182 - accuracy: 0.5944 - val_loss: 1.5434 - val_accuracy: 0.5398\n",
            "Epoch 21/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1849 - accuracy: 0.6060 - val_loss: 1.5849 - val_accuracy: 0.5288\n",
            "Epoch 22/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1676 - accuracy: 0.6094 - val_loss: 1.5691 - val_accuracy: 0.5342\n",
            "Epoch 23/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.1422 - accuracy: 0.6176 - val_loss: 1.5675 - val_accuracy: 0.5391\n",
            "Epoch 24/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.1237 - accuracy: 0.6253 - val_loss: 1.6074 - val_accuracy: 0.5393\n",
            "Epoch 25/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.1034 - accuracy: 0.6303 - val_loss: 1.6162 - val_accuracy: 0.5320\n",
            "Epoch 26/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0778 - accuracy: 0.6374 - val_loss: 1.6151 - val_accuracy: 0.5313\n",
            "Epoch 27/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.0583 - accuracy: 0.6432 - val_loss: 1.5670 - val_accuracy: 0.5386\n",
            "Epoch 28/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.0490 - accuracy: 0.6470 - val_loss: 1.6008 - val_accuracy: 0.5471\n",
            "Epoch 29/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.0422 - accuracy: 0.6509 - val_loss: 1.6067 - val_accuracy: 0.5443\n",
            "Epoch 30/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0270 - accuracy: 0.6522 - val_loss: 1.6285 - val_accuracy: 0.5355\n",
            "Epoch 31/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0087 - accuracy: 0.6597 - val_loss: 1.6284 - val_accuracy: 0.5462\n",
            "Epoch 32/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.9832 - accuracy: 0.6663 - val_loss: 1.6460 - val_accuracy: 0.5422\n",
            "Epoch 33/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.9729 - accuracy: 0.6696 - val_loss: 1.6549 - val_accuracy: 0.5395\n",
            "Epoch 34/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.9651 - accuracy: 0.6709 - val_loss: 1.7508 - val_accuracy: 0.5342\n",
            "Epoch 35/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9575 - accuracy: 0.6773 - val_loss: 1.6482 - val_accuracy: 0.5406\n",
            "Epoch 36/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9450 - accuracy: 0.6798 - val_loss: 1.7091 - val_accuracy: 0.5422\n",
            "Epoch 37/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.9255 - accuracy: 0.6874 - val_loss: 1.7217 - val_accuracy: 0.5462\n",
            "Epoch 38/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.9129 - accuracy: 0.6885 - val_loss: 1.7079 - val_accuracy: 0.5358\n",
            "Epoch 39/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.8993 - accuracy: 0.6938 - val_loss: 1.6863 - val_accuracy: 0.5302\n",
            "Epoch 40/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8973 - accuracy: 0.6938 - val_loss: 1.7136 - val_accuracy: 0.5409\n",
            "Epoch 41/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.8803 - accuracy: 0.7018 - val_loss: 1.6903 - val_accuracy: 0.5430\n",
            "Epoch 42/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.8807 - accuracy: 0.7010 - val_loss: 1.7045 - val_accuracy: 0.5387\n",
            "Epoch 43/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8671 - accuracy: 0.7038 - val_loss: 1.7303 - val_accuracy: 0.5377\n",
            "Epoch 44/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8558 - accuracy: 0.7076 - val_loss: 1.7181 - val_accuracy: 0.5477\n",
            "Epoch 45/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8535 - accuracy: 0.7094 - val_loss: 1.7419 - val_accuracy: 0.5368\n",
            "Epoch 46/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.8354 - accuracy: 0.7165 - val_loss: 1.7465 - val_accuracy: 0.5386\n",
            "Epoch 47/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.8331 - accuracy: 0.7152 - val_loss: 1.7416 - val_accuracy: 0.5465\n",
            "Epoch 48/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.8337 - accuracy: 0.7165 - val_loss: 1.7151 - val_accuracy: 0.5427\n",
            "Epoch 49/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.8151 - accuracy: 0.7229 - val_loss: 1.7829 - val_accuracy: 0.5405\n",
            "Epoch 50/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.8105 - accuracy: 0.7235 - val_loss: 1.7512 - val_accuracy: 0.5475\n",
            "Epoch 51/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.8047 - accuracy: 0.7269 - val_loss: 1.8248 - val_accuracy: 0.5456\n",
            "Epoch 52/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8027 - accuracy: 0.7270 - val_loss: 1.7472 - val_accuracy: 0.5435\n",
            "Epoch 53/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7889 - accuracy: 0.7294 - val_loss: 1.8062 - val_accuracy: 0.5445\n",
            "Epoch 54/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7921 - accuracy: 0.7292 - val_loss: 1.8090 - val_accuracy: 0.5403\n",
            "Epoch 55/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7816 - accuracy: 0.7330 - val_loss: 1.7184 - val_accuracy: 0.5449\n",
            "Epoch 56/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7743 - accuracy: 0.7360 - val_loss: 1.7984 - val_accuracy: 0.5375\n",
            "Epoch 57/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7631 - accuracy: 0.7406 - val_loss: 1.7895 - val_accuracy: 0.5425\n",
            "Epoch 58/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7602 - accuracy: 0.7422 - val_loss: 1.8454 - val_accuracy: 0.5448\n",
            "Epoch 59/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7588 - accuracy: 0.7419 - val_loss: 1.8080 - val_accuracy: 0.5426\n",
            "Epoch 60/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7471 - accuracy: 0.7458 - val_loss: 1.8056 - val_accuracy: 0.5456\n",
            "Epoch 61/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7391 - accuracy: 0.7493 - val_loss: 1.7615 - val_accuracy: 0.5465\n",
            "Epoch 62/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7428 - accuracy: 0.7480 - val_loss: 1.7917 - val_accuracy: 0.5474\n",
            "Epoch 63/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7311 - accuracy: 0.7518 - val_loss: 1.8166 - val_accuracy: 0.5432\n",
            "Epoch 64/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7338 - accuracy: 0.7518 - val_loss: 1.8122 - val_accuracy: 0.5383\n",
            "Epoch 65/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7269 - accuracy: 0.7540 - val_loss: 1.8113 - val_accuracy: 0.5505\n",
            "Epoch 66/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7205 - accuracy: 0.7525 - val_loss: 1.8297 - val_accuracy: 0.5477\n",
            "Epoch 67/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7187 - accuracy: 0.7562 - val_loss: 1.8699 - val_accuracy: 0.5489\n",
            "Epoch 68/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7148 - accuracy: 0.7586 - val_loss: 1.8223 - val_accuracy: 0.5435\n",
            "Epoch 69/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7139 - accuracy: 0.7550 - val_loss: 1.8241 - val_accuracy: 0.5487\n",
            "Epoch 70/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7112 - accuracy: 0.7576 - val_loss: 1.8553 - val_accuracy: 0.5438\n",
            "Epoch 71/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6987 - accuracy: 0.7608 - val_loss: 1.8573 - val_accuracy: 0.5459\n",
            "Epoch 72/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7056 - accuracy: 0.7622 - val_loss: 1.8876 - val_accuracy: 0.5477\n",
            "Epoch 73/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.6945 - accuracy: 0.7620 - val_loss: 1.8778 - val_accuracy: 0.5515\n",
            "Epoch 74/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6775 - accuracy: 0.7682 - val_loss: 1.8934 - val_accuracy: 0.5453\n",
            "Epoch 75/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6757 - accuracy: 0.7680 - val_loss: 1.8565 - val_accuracy: 0.5446\n",
            "Epoch 76/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6751 - accuracy: 0.7684 - val_loss: 1.8654 - val_accuracy: 0.5458\n",
            "Epoch 77/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6704 - accuracy: 0.7737 - val_loss: 1.8910 - val_accuracy: 0.5490\n",
            "Epoch 78/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6654 - accuracy: 0.7718 - val_loss: 1.9035 - val_accuracy: 0.5413\n",
            "Epoch 79/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6693 - accuracy: 0.7706 - val_loss: 1.9112 - val_accuracy: 0.5421\n",
            "Epoch 80/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6679 - accuracy: 0.7722 - val_loss: 1.8592 - val_accuracy: 0.5428\n",
            "Epoch 81/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6628 - accuracy: 0.7739 - val_loss: 1.8735 - val_accuracy: 0.5440\n",
            "Epoch 82/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.6540 - accuracy: 0.7790 - val_loss: 1.8537 - val_accuracy: 0.5446\n",
            "Epoch 83/100\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.6578 - accuracy: 0.7753 - val_loss: 1.9333 - val_accuracy: 0.5455\n",
            "Epoch 84/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6531 - accuracy: 0.7773 - val_loss: 1.8766 - val_accuracy: 0.5428\n",
            "Epoch 85/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6472 - accuracy: 0.7798 - val_loss: 1.9066 - val_accuracy: 0.5450\n",
            "Epoch 86/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6428 - accuracy: 0.7811 - val_loss: 1.8629 - val_accuracy: 0.5468\n",
            "Epoch 87/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6354 - accuracy: 0.7831 - val_loss: 1.9286 - val_accuracy: 0.5431\n",
            "Epoch 88/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6355 - accuracy: 0.7837 - val_loss: 1.9069 - val_accuracy: 0.5408\n",
            "Epoch 89/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6328 - accuracy: 0.7850 - val_loss: 1.9456 - val_accuracy: 0.5481\n",
            "Epoch 90/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6260 - accuracy: 0.7858 - val_loss: 1.9281 - val_accuracy: 0.5454\n",
            "Epoch 91/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6265 - accuracy: 0.7856 - val_loss: 1.9911 - val_accuracy: 0.5453\n",
            "Epoch 92/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6370 - accuracy: 0.7846 - val_loss: 1.9525 - val_accuracy: 0.5424\n",
            "Epoch 93/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6214 - accuracy: 0.7889 - val_loss: 1.8823 - val_accuracy: 0.5439\n",
            "Epoch 94/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6198 - accuracy: 0.7892 - val_loss: 1.9325 - val_accuracy: 0.5410\n",
            "Epoch 95/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6098 - accuracy: 0.7903 - val_loss: 1.9583 - val_accuracy: 0.5404\n",
            "Epoch 96/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6158 - accuracy: 0.7903 - val_loss: 1.9612 - val_accuracy: 0.5416\n",
            "Epoch 97/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6136 - accuracy: 0.7913 - val_loss: 1.9540 - val_accuracy: 0.5478\n",
            "Epoch 98/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6076 - accuracy: 0.7950 - val_loss: 1.9889 - val_accuracy: 0.5434\n",
            "Epoch 99/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6038 - accuracy: 0.7927 - val_loss: 1.9431 - val_accuracy: 0.5422\n",
            "Epoch 100/100\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6021 - accuracy: 0.7963 - val_loss: 1.9628 - val_accuracy: 0.5425\n",
            "test accuracy:  0.5515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quihZEo451_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Examining loss on TensorBoard\n",
        "%tensorboard --logdir logs/scalars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJZJHHGuKSoH",
        "colab_type": "text"
      },
      "source": [
        "###Optimizing hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLkvSMG4vBYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Storing the model for random search\n",
        "def build_model(hp):\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters=hp.Choice(\n",
        "        'first_layer_filters',\n",
        "        values=[16,32,64],\n",
        "        default=32\n",
        "    ), kernel_size=(3,3),\n",
        "    activation=tf.nn.relu,padding='same',\n",
        "    input_shape=( 32, 32, 3)))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters=hp.Choice(\n",
        "        'second_layer_filters',\n",
        "        values=[16,32,64],\n",
        "        default=32\n",
        "    ), kernel_size=(3,3),\n",
        "    activation=tf.nn.relu,padding='same',\n",
        "    input_shape=( 32, 32, 3)))\n",
        "\n",
        "  model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "  model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters=hp.Choice(\n",
        "        'third_layer_filters',\n",
        "        values=[32,64,128],\n",
        "        default=64\n",
        "    ), kernel_size=(3,3),\n",
        "    activation=tf.nn.relu,padding='same'))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters=hp.Choice(\n",
        "        'fourth_layer_filters',\n",
        "        values=[32,64,128],\n",
        "        default=64\n",
        "    ), kernel_size=(3,3),\n",
        "    activation=tf.nn.relu,padding='same'))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "  model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(units=hp.Choice(\n",
        "        'dense_units',\n",
        "        values=[64,128,256],\n",
        "        default=128\n",
        "    ), activation=tf.nn.relu))\n",
        "\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(units=20,activation=tf.nn.softmax))\n",
        "\n",
        "  #Compiling model using an Adam optimizer\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMFDLXt5pDLv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bb79e7f4-91fc-4ab9-f48d-59140723b866"
      },
      "source": [
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "#Storing random search parameters\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    seed=42,\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='random_search',\n",
        "    project_name='cifar20'\n",
        ")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project random_search/cifar20/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from random_search/cifar20/tuner0.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUtdxiidpJFk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e92b8228-a5b6-473b-f1a3-d586fc740133"
      },
      "source": [
        "#Random search\n",
        "tuner.search(x_input, y_input,\n",
        "             epochs=50,\n",
        "             batch_size=64,\n",
        "             validation_data=(x_valid, y_valid))\n",
        "\n",
        "#Printing 'best' model performance\n",
        "print(tuner.get_best_models()[0].summary())\n",
        "print(tuner.get_best_hyperparameters()[0].values)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.6185 - accuracy: 0.1893 - val_loss: 2.3249 - val_accuracy: 0.2938\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.2826 - accuracy: 0.2943 - val_loss: 2.0122 - val_accuracy: 0.3826\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.1089 - accuracy: 0.3490 - val_loss: 1.9080 - val_accuracy: 0.4028\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.9792 - accuracy: 0.3821 - val_loss: 1.7757 - val_accuracy: 0.4487\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.8784 - accuracy: 0.4143 - val_loss: 1.7130 - val_accuracy: 0.4633\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.7948 - accuracy: 0.4396 - val_loss: 1.7104 - val_accuracy: 0.4648\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.7144 - accuracy: 0.4577 - val_loss: 1.6159 - val_accuracy: 0.4982\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.6550 - accuracy: 0.4756 - val_loss: 1.5812 - val_accuracy: 0.5064\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.5845 - accuracy: 0.4926 - val_loss: 1.5773 - val_accuracy: 0.5102\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.5390 - accuracy: 0.5075 - val_loss: 1.5596 - val_accuracy: 0.5131\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4886 - accuracy: 0.5204 - val_loss: 1.5432 - val_accuracy: 0.5205\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4367 - accuracy: 0.5354 - val_loss: 1.5453 - val_accuracy: 0.5222\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3939 - accuracy: 0.5484 - val_loss: 1.5265 - val_accuracy: 0.5294\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3622 - accuracy: 0.5578 - val_loss: 1.5321 - val_accuracy: 0.5315\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3202 - accuracy: 0.5712 - val_loss: 1.5253 - val_accuracy: 0.5370\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2870 - accuracy: 0.5802 - val_loss: 1.5374 - val_accuracy: 0.5314\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2538 - accuracy: 0.5876 - val_loss: 1.5399 - val_accuracy: 0.5308\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2309 - accuracy: 0.5952 - val_loss: 1.5480 - val_accuracy: 0.5336\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1985 - accuracy: 0.6035 - val_loss: 1.5306 - val_accuracy: 0.5404\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1699 - accuracy: 0.6148 - val_loss: 1.6042 - val_accuracy: 0.5322\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1518 - accuracy: 0.6195 - val_loss: 1.5313 - val_accuracy: 0.5368\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1297 - accuracy: 0.6238 - val_loss: 1.5821 - val_accuracy: 0.5324\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0996 - accuracy: 0.6315 - val_loss: 1.5602 - val_accuracy: 0.5448\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0786 - accuracy: 0.6427 - val_loss: 1.5713 - val_accuracy: 0.5421\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0598 - accuracy: 0.6449 - val_loss: 1.5758 - val_accuracy: 0.5423\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0402 - accuracy: 0.6522 - val_loss: 1.5731 - val_accuracy: 0.5499\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0187 - accuracy: 0.6574 - val_loss: 1.5770 - val_accuracy: 0.5472\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9963 - accuracy: 0.6654 - val_loss: 1.5885 - val_accuracy: 0.5476\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9931 - accuracy: 0.6645 - val_loss: 1.5841 - val_accuracy: 0.5502\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9778 - accuracy: 0.6720 - val_loss: 1.6105 - val_accuracy: 0.5455\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9636 - accuracy: 0.6759 - val_loss: 1.6373 - val_accuracy: 0.5481\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9431 - accuracy: 0.6799 - val_loss: 1.6586 - val_accuracy: 0.5461\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9382 - accuracy: 0.6852 - val_loss: 1.6480 - val_accuracy: 0.5468\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9280 - accuracy: 0.6875 - val_loss: 1.6603 - val_accuracy: 0.5452\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9062 - accuracy: 0.6946 - val_loss: 1.6296 - val_accuracy: 0.5489\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8944 - accuracy: 0.6973 - val_loss: 1.6778 - val_accuracy: 0.5481\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8912 - accuracy: 0.7010 - val_loss: 1.6795 - val_accuracy: 0.5525\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8716 - accuracy: 0.7046 - val_loss: 1.6296 - val_accuracy: 0.5507\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8639 - accuracy: 0.7082 - val_loss: 1.6699 - val_accuracy: 0.5524\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8460 - accuracy: 0.7116 - val_loss: 1.7239 - val_accuracy: 0.5475\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8549 - accuracy: 0.7115 - val_loss: 1.6912 - val_accuracy: 0.5543\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8275 - accuracy: 0.7201 - val_loss: 1.7410 - val_accuracy: 0.5491\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8165 - accuracy: 0.7253 - val_loss: 1.7453 - val_accuracy: 0.5438\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8060 - accuracy: 0.7283 - val_loss: 1.6922 - val_accuracy: 0.5512\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7973 - accuracy: 0.7292 - val_loss: 1.7391 - val_accuracy: 0.5452\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8009 - accuracy: 0.7293 - val_loss: 1.7219 - val_accuracy: 0.5419\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7898 - accuracy: 0.7327 - val_loss: 1.7360 - val_accuracy: 0.5499\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7743 - accuracy: 0.7370 - val_loss: 1.7423 - val_accuracy: 0.5493\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7699 - accuracy: 0.7426 - val_loss: 1.7619 - val_accuracy: 0.5493\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7651 - accuracy: 0.7402 - val_loss: 1.7416 - val_accuracy: 0.5512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 8f9ed6e999f633140b7f8db46da2c72c</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5543000102043152</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_units: 128</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-first_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-fourth_layer_filters: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-num_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-second_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-third_layer_filters: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.6279 - accuracy: 0.1865 - val_loss: 2.3129 - val_accuracy: 0.2893\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.3225 - accuracy: 0.2846 - val_loss: 2.1374 - val_accuracy: 0.3381\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.1558 - accuracy: 0.3293 - val_loss: 1.9362 - val_accuracy: 0.3895\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.0510 - accuracy: 0.3606 - val_loss: 1.8779 - val_accuracy: 0.4198\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.9575 - accuracy: 0.3917 - val_loss: 1.7777 - val_accuracy: 0.4513\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.8762 - accuracy: 0.4122 - val_loss: 1.7394 - val_accuracy: 0.4563\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.8091 - accuracy: 0.4326 - val_loss: 1.6834 - val_accuracy: 0.4773\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.7586 - accuracy: 0.4456 - val_loss: 1.6497 - val_accuracy: 0.4833\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.7049 - accuracy: 0.4624 - val_loss: 1.6391 - val_accuracy: 0.4847\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6626 - accuracy: 0.4686 - val_loss: 1.6177 - val_accuracy: 0.4950\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.6072 - accuracy: 0.4904 - val_loss: 1.6061 - val_accuracy: 0.4966\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.5746 - accuracy: 0.4971 - val_loss: 1.5832 - val_accuracy: 0.5074\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5404 - accuracy: 0.5059 - val_loss: 1.5601 - val_accuracy: 0.5100\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5110 - accuracy: 0.5116 - val_loss: 1.5465 - val_accuracy: 0.5173\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4786 - accuracy: 0.5233 - val_loss: 1.5178 - val_accuracy: 0.5234\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4472 - accuracy: 0.5329 - val_loss: 1.5410 - val_accuracy: 0.5143\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4093 - accuracy: 0.5418 - val_loss: 1.5711 - val_accuracy: 0.5069\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3940 - accuracy: 0.5457 - val_loss: 1.5615 - val_accuracy: 0.5169\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3652 - accuracy: 0.5549 - val_loss: 1.5176 - val_accuracy: 0.5312\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3462 - accuracy: 0.5615 - val_loss: 1.5419 - val_accuracy: 0.5264\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3175 - accuracy: 0.5707 - val_loss: 1.5314 - val_accuracy: 0.5295\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2896 - accuracy: 0.5774 - val_loss: 1.5183 - val_accuracy: 0.5329\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2819 - accuracy: 0.5795 - val_loss: 1.5548 - val_accuracy: 0.5255\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2600 - accuracy: 0.5854 - val_loss: 1.5495 - val_accuracy: 0.5293\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2453 - accuracy: 0.5882 - val_loss: 1.5392 - val_accuracy: 0.5290\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2297 - accuracy: 0.5962 - val_loss: 1.5464 - val_accuracy: 0.5300\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2136 - accuracy: 0.5986 - val_loss: 1.5329 - val_accuracy: 0.5384\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1923 - accuracy: 0.6069 - val_loss: 1.5567 - val_accuracy: 0.5361\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1810 - accuracy: 0.6085 - val_loss: 1.5758 - val_accuracy: 0.5271\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1634 - accuracy: 0.6117 - val_loss: 1.5657 - val_accuracy: 0.5341\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1569 - accuracy: 0.6185 - val_loss: 1.5505 - val_accuracy: 0.5321\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1484 - accuracy: 0.6158 - val_loss: 1.5624 - val_accuracy: 0.5390\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1324 - accuracy: 0.6245 - val_loss: 1.5592 - val_accuracy: 0.5316\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1228 - accuracy: 0.6308 - val_loss: 1.5982 - val_accuracy: 0.5326\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1104 - accuracy: 0.6295 - val_loss: 1.5607 - val_accuracy: 0.5433\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1013 - accuracy: 0.6311 - val_loss: 1.5386 - val_accuracy: 0.5410\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1001 - accuracy: 0.6339 - val_loss: 1.5691 - val_accuracy: 0.5402\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0908 - accuracy: 0.6337 - val_loss: 1.5589 - val_accuracy: 0.5432\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0659 - accuracy: 0.6434 - val_loss: 1.5773 - val_accuracy: 0.5409\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0636 - accuracy: 0.6461 - val_loss: 1.5571 - val_accuracy: 0.5360\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0517 - accuracy: 0.6478 - val_loss: 1.6217 - val_accuracy: 0.5307\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0487 - accuracy: 0.6465 - val_loss: 1.6260 - val_accuracy: 0.5340\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0396 - accuracy: 0.6517 - val_loss: 1.6432 - val_accuracy: 0.5360\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0231 - accuracy: 0.6563 - val_loss: 1.6239 - val_accuracy: 0.5404\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0219 - accuracy: 0.6555 - val_loss: 1.6501 - val_accuracy: 0.5401\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0188 - accuracy: 0.6564 - val_loss: 1.6545 - val_accuracy: 0.5322\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0152 - accuracy: 0.6546 - val_loss: 1.5943 - val_accuracy: 0.5388\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0015 - accuracy: 0.6633 - val_loss: 1.5921 - val_accuracy: 0.5400\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0015 - accuracy: 0.6634 - val_loss: 1.6240 - val_accuracy: 0.5350\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.9942 - accuracy: 0.6649 - val_loss: 1.5990 - val_accuracy: 0.5416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: dd1f08e7fc518889a4d541315a6beaef</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5432999730110168</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_units: 128</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-first_layer_filters: 16</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-fourth_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-num_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-second_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-third_layer_filters: 128</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.5271 - accuracy: 0.2158 - val_loss: 2.2249 - val_accuracy: 0.3106\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.1904 - accuracy: 0.3241 - val_loss: 2.0085 - val_accuracy: 0.3863\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.0204 - accuracy: 0.3754 - val_loss: 1.8890 - val_accuracy: 0.4166\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.8980 - accuracy: 0.4075 - val_loss: 1.7839 - val_accuracy: 0.4430\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.7998 - accuracy: 0.4387 - val_loss: 1.7369 - val_accuracy: 0.4569\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.7089 - accuracy: 0.4643 - val_loss: 1.6898 - val_accuracy: 0.4762\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.6321 - accuracy: 0.4865 - val_loss: 1.6411 - val_accuracy: 0.4908\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.5675 - accuracy: 0.5035 - val_loss: 1.6520 - val_accuracy: 0.4877\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4954 - accuracy: 0.5218 - val_loss: 1.6104 - val_accuracy: 0.5024\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4384 - accuracy: 0.5411 - val_loss: 1.5905 - val_accuracy: 0.5072\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3823 - accuracy: 0.5576 - val_loss: 1.5943 - val_accuracy: 0.5145\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3415 - accuracy: 0.5670 - val_loss: 1.6170 - val_accuracy: 0.5117\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.2859 - accuracy: 0.5829 - val_loss: 1.5790 - val_accuracy: 0.5215\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.2497 - accuracy: 0.5934 - val_loss: 1.6034 - val_accuracy: 0.5218\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2070 - accuracy: 0.6064 - val_loss: 1.6155 - val_accuracy: 0.5158\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1699 - accuracy: 0.6170 - val_loss: 1.6034 - val_accuracy: 0.5223\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1325 - accuracy: 0.6284 - val_loss: 1.6455 - val_accuracy: 0.5232\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1027 - accuracy: 0.6369 - val_loss: 1.6160 - val_accuracy: 0.5284\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0715 - accuracy: 0.6464 - val_loss: 1.6658 - val_accuracy: 0.5214\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0520 - accuracy: 0.6529 - val_loss: 1.6242 - val_accuracy: 0.5251\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0214 - accuracy: 0.6624 - val_loss: 1.6615 - val_accuracy: 0.5232\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0023 - accuracy: 0.6690 - val_loss: 1.6917 - val_accuracy: 0.5222\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9771 - accuracy: 0.6747 - val_loss: 1.6735 - val_accuracy: 0.5265\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9643 - accuracy: 0.6811 - val_loss: 1.6946 - val_accuracy: 0.5262\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9387 - accuracy: 0.6857 - val_loss: 1.6829 - val_accuracy: 0.5234\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9185 - accuracy: 0.6965 - val_loss: 1.7274 - val_accuracy: 0.5183\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9062 - accuracy: 0.6973 - val_loss: 1.7536 - val_accuracy: 0.5210\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8902 - accuracy: 0.7026 - val_loss: 1.7297 - val_accuracy: 0.5238\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8683 - accuracy: 0.7107 - val_loss: 1.7772 - val_accuracy: 0.5203\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8737 - accuracy: 0.7064 - val_loss: 1.7360 - val_accuracy: 0.5241\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8515 - accuracy: 0.7154 - val_loss: 1.7471 - val_accuracy: 0.5233\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8384 - accuracy: 0.7179 - val_loss: 1.7714 - val_accuracy: 0.5260\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8183 - accuracy: 0.7247 - val_loss: 1.7607 - val_accuracy: 0.5264\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8092 - accuracy: 0.7266 - val_loss: 1.7640 - val_accuracy: 0.5238\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7971 - accuracy: 0.7300 - val_loss: 1.7987 - val_accuracy: 0.5205\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7868 - accuracy: 0.7344 - val_loss: 1.8046 - val_accuracy: 0.5206\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7888 - accuracy: 0.7359 - val_loss: 1.7748 - val_accuracy: 0.5227\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7668 - accuracy: 0.7418 - val_loss: 1.8258 - val_accuracy: 0.5244\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7607 - accuracy: 0.7429 - val_loss: 1.8275 - val_accuracy: 0.5214\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7629 - accuracy: 0.7438 - val_loss: 1.8210 - val_accuracy: 0.5189\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7331 - accuracy: 0.7541 - val_loss: 1.8427 - val_accuracy: 0.5273\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7392 - accuracy: 0.7501 - val_loss: 1.8732 - val_accuracy: 0.5198\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7365 - accuracy: 0.7542 - val_loss: 1.8662 - val_accuracy: 0.5228\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7269 - accuracy: 0.7571 - val_loss: 1.8820 - val_accuracy: 0.5262\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7151 - accuracy: 0.7604 - val_loss: 1.8584 - val_accuracy: 0.5267\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6952 - accuracy: 0.7669 - val_loss: 1.8655 - val_accuracy: 0.5158\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7020 - accuracy: 0.7630 - val_loss: 1.8893 - val_accuracy: 0.5241\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7008 - accuracy: 0.7644 - val_loss: 1.8947 - val_accuracy: 0.5223\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6927 - accuracy: 0.7665 - val_loss: 1.9044 - val_accuracy: 0.5245\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6878 - accuracy: 0.7709 - val_loss: 1.8917 - val_accuracy: 0.5162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: d8d180da0877e2436a9c5d7917db93f1</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5284000039100647</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_units: 256</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-first_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-fourth_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-num_filters: 16</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-second_layer_filters: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-third_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 2.5554 - accuracy: 0.2087 - val_loss: 2.3108 - val_accuracy: 0.2888\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.2109 - accuracy: 0.3206 - val_loss: 2.1146 - val_accuracy: 0.3481\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.0373 - accuracy: 0.3704 - val_loss: 1.9261 - val_accuracy: 0.4064\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.9107 - accuracy: 0.4061 - val_loss: 1.8232 - val_accuracy: 0.4381\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.8108 - accuracy: 0.4352 - val_loss: 1.7922 - val_accuracy: 0.4489\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.7219 - accuracy: 0.4596 - val_loss: 1.7197 - val_accuracy: 0.4663\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.6436 - accuracy: 0.4816 - val_loss: 1.6752 - val_accuracy: 0.4881\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.5675 - accuracy: 0.5024 - val_loss: 1.6578 - val_accuracy: 0.4940\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.5130 - accuracy: 0.5190 - val_loss: 1.5949 - val_accuracy: 0.5125\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4504 - accuracy: 0.5350 - val_loss: 1.6335 - val_accuracy: 0.5028\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4007 - accuracy: 0.5490 - val_loss: 1.5741 - val_accuracy: 0.5163\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.3534 - accuracy: 0.5643 - val_loss: 1.5983 - val_accuracy: 0.5117\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.3059 - accuracy: 0.5772 - val_loss: 1.6270 - val_accuracy: 0.5107\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2628 - accuracy: 0.5901 - val_loss: 1.5973 - val_accuracy: 0.5149\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2187 - accuracy: 0.6026 - val_loss: 1.6238 - val_accuracy: 0.5129\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1825 - accuracy: 0.6120 - val_loss: 1.6737 - val_accuracy: 0.5050\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1472 - accuracy: 0.6248 - val_loss: 1.6651 - val_accuracy: 0.5088\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.1086 - accuracy: 0.6335 - val_loss: 1.6422 - val_accuracy: 0.5189\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0841 - accuracy: 0.6454 - val_loss: 1.6277 - val_accuracy: 0.5223\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0575 - accuracy: 0.6496 - val_loss: 1.6690 - val_accuracy: 0.5193\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0327 - accuracy: 0.6598 - val_loss: 1.6949 - val_accuracy: 0.5163\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0008 - accuracy: 0.6675 - val_loss: 1.7125 - val_accuracy: 0.5135\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9788 - accuracy: 0.6735 - val_loss: 1.7329 - val_accuracy: 0.5169\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9625 - accuracy: 0.6815 - val_loss: 1.6913 - val_accuracy: 0.5244\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9367 - accuracy: 0.6869 - val_loss: 1.7264 - val_accuracy: 0.5223\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9120 - accuracy: 0.6966 - val_loss: 1.7685 - val_accuracy: 0.5233\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9011 - accuracy: 0.7006 - val_loss: 1.7401 - val_accuracy: 0.5245\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8794 - accuracy: 0.7062 - val_loss: 1.7958 - val_accuracy: 0.5206\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8694 - accuracy: 0.7106 - val_loss: 1.7564 - val_accuracy: 0.5125\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8461 - accuracy: 0.7163 - val_loss: 1.7992 - val_accuracy: 0.5165\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8264 - accuracy: 0.7232 - val_loss: 1.7471 - val_accuracy: 0.5216\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8133 - accuracy: 0.7252 - val_loss: 1.8124 - val_accuracy: 0.5190\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7954 - accuracy: 0.7331 - val_loss: 1.8525 - val_accuracy: 0.5115\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7841 - accuracy: 0.7388 - val_loss: 1.8344 - val_accuracy: 0.5222\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7808 - accuracy: 0.7370 - val_loss: 1.8572 - val_accuracy: 0.5193\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7702 - accuracy: 0.7399 - val_loss: 1.8403 - val_accuracy: 0.5216\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7491 - accuracy: 0.7468 - val_loss: 1.8944 - val_accuracy: 0.5063\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7516 - accuracy: 0.7490 - val_loss: 1.9166 - val_accuracy: 0.5077\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7411 - accuracy: 0.7507 - val_loss: 1.8164 - val_accuracy: 0.5214\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7279 - accuracy: 0.7534 - val_loss: 1.8797 - val_accuracy: 0.5177\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7179 - accuracy: 0.7591 - val_loss: 1.8757 - val_accuracy: 0.5151\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7120 - accuracy: 0.7616 - val_loss: 1.8905 - val_accuracy: 0.5220\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6939 - accuracy: 0.7670 - val_loss: 1.9336 - val_accuracy: 0.5140\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6807 - accuracy: 0.7701 - val_loss: 1.8895 - val_accuracy: 0.5257\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6720 - accuracy: 0.7733 - val_loss: 1.9286 - val_accuracy: 0.5279\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6665 - accuracy: 0.7758 - val_loss: 1.8786 - val_accuracy: 0.5224\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6589 - accuracy: 0.7778 - val_loss: 1.9243 - val_accuracy: 0.5216\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6488 - accuracy: 0.7807 - val_loss: 1.9729 - val_accuracy: 0.5133\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6425 - accuracy: 0.7849 - val_loss: 1.9314 - val_accuracy: 0.5197\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6410 - accuracy: 0.7835 - val_loss: 1.9222 - val_accuracy: 0.5190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 72cef30b9db7b225e8e9d7f9be785d3c</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.527899980545044</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_units: 256</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-first_layer_filters: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-fourth_layer_filters: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-num_filters: 16</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-second_layer_filters: 16</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-third_layer_filters: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.5262 - accuracy: 0.2190 - val_loss: 2.2733 - val_accuracy: 0.2999\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.1785 - accuracy: 0.3283 - val_loss: 1.9705 - val_accuracy: 0.3934\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.0054 - accuracy: 0.3800 - val_loss: 1.8131 - val_accuracy: 0.4358\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.8793 - accuracy: 0.4165 - val_loss: 1.7412 - val_accuracy: 0.4567\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.7861 - accuracy: 0.4423 - val_loss: 1.6768 - val_accuracy: 0.4755\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6972 - accuracy: 0.4677 - val_loss: 1.6322 - val_accuracy: 0.4911\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6312 - accuracy: 0.4864 - val_loss: 1.6134 - val_accuracy: 0.4934\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5796 - accuracy: 0.4987 - val_loss: 1.5856 - val_accuracy: 0.5034\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5161 - accuracy: 0.5178 - val_loss: 1.5616 - val_accuracy: 0.5091\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.4614 - accuracy: 0.5335 - val_loss: 1.5813 - val_accuracy: 0.5061\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4146 - accuracy: 0.5436 - val_loss: 1.5448 - val_accuracy: 0.5174\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3665 - accuracy: 0.5624 - val_loss: 1.5801 - val_accuracy: 0.5159\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3246 - accuracy: 0.5706 - val_loss: 1.5549 - val_accuracy: 0.5224\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.2888 - accuracy: 0.5827 - val_loss: 1.5758 - val_accuracy: 0.5192\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2552 - accuracy: 0.5918 - val_loss: 1.5450 - val_accuracy: 0.5280\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2260 - accuracy: 0.6022 - val_loss: 1.5423 - val_accuracy: 0.5284\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1890 - accuracy: 0.6104 - val_loss: 1.5489 - val_accuracy: 0.5289\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1692 - accuracy: 0.6147 - val_loss: 1.5670 - val_accuracy: 0.5283\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1428 - accuracy: 0.6242 - val_loss: 1.6296 - val_accuracy: 0.5179\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1119 - accuracy: 0.6323 - val_loss: 1.5657 - val_accuracy: 0.5275\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0943 - accuracy: 0.6390 - val_loss: 1.5890 - val_accuracy: 0.5310\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0704 - accuracy: 0.6442 - val_loss: 1.5973 - val_accuracy: 0.5339\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0541 - accuracy: 0.6497 - val_loss: 1.5793 - val_accuracy: 0.5339\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.0324 - accuracy: 0.6578 - val_loss: 1.5886 - val_accuracy: 0.5321\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0164 - accuracy: 0.6617 - val_loss: 1.6733 - val_accuracy: 0.5145\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.9968 - accuracy: 0.6687 - val_loss: 1.6015 - val_accuracy: 0.5323\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.9838 - accuracy: 0.6710 - val_loss: 1.6187 - val_accuracy: 0.5305\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.9582 - accuracy: 0.6789 - val_loss: 1.6211 - val_accuracy: 0.5359\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.9459 - accuracy: 0.6835 - val_loss: 1.6452 - val_accuracy: 0.5262\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.9395 - accuracy: 0.6854 - val_loss: 1.6533 - val_accuracy: 0.5300\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.9243 - accuracy: 0.6910 - val_loss: 1.6145 - val_accuracy: 0.5366\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.9033 - accuracy: 0.6966 - val_loss: 1.6587 - val_accuracy: 0.5305\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.8940 - accuracy: 0.6985 - val_loss: 1.6420 - val_accuracy: 0.5322\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8945 - accuracy: 0.6986 - val_loss: 1.6587 - val_accuracy: 0.5281\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8868 - accuracy: 0.7016 - val_loss: 1.6711 - val_accuracy: 0.5355\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8582 - accuracy: 0.7088 - val_loss: 1.7107 - val_accuracy: 0.5271\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8672 - accuracy: 0.7085 - val_loss: 1.6405 - val_accuracy: 0.5349\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8418 - accuracy: 0.7186 - val_loss: 1.7123 - val_accuracy: 0.5312\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8360 - accuracy: 0.7186 - val_loss: 1.7219 - val_accuracy: 0.5341\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.8413 - accuracy: 0.7173 - val_loss: 1.6598 - val_accuracy: 0.5330\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.8277 - accuracy: 0.7210 - val_loss: 1.7434 - val_accuracy: 0.5257\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8183 - accuracy: 0.7243 - val_loss: 1.7188 - val_accuracy: 0.5283\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8117 - accuracy: 0.7266 - val_loss: 1.7269 - val_accuracy: 0.5280\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7977 - accuracy: 0.7309 - val_loss: 1.7517 - val_accuracy: 0.5295\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.7956 - accuracy: 0.7307 - val_loss: 1.7480 - val_accuracy: 0.5297\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7878 - accuracy: 0.7326 - val_loss: 1.7393 - val_accuracy: 0.5358\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7801 - accuracy: 0.7371 - val_loss: 1.7660 - val_accuracy: 0.5262\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7760 - accuracy: 0.7379 - val_loss: 1.7129 - val_accuracy: 0.5328\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7791 - accuracy: 0.7376 - val_loss: 1.7646 - val_accuracy: 0.5338\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 0.7739 - accuracy: 0.7393 - val_loss: 1.7398 - val_accuracy: 0.5323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 72379f4d4b1addea7a8383630dabadf4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5365999937057495</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_units: 256</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-first_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-fourth_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-num_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-second_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-third_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.5378 - accuracy: 0.2158 - val_loss: 2.1920 - val_accuracy: 0.3276\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.2050 - accuracy: 0.3215 - val_loss: 2.0245 - val_accuracy: 0.3777\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.0260 - accuracy: 0.3716 - val_loss: 1.8382 - val_accuracy: 0.4290\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.8912 - accuracy: 0.4108 - val_loss: 1.7482 - val_accuracy: 0.4599\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.7654 - accuracy: 0.4494 - val_loss: 1.6670 - val_accuracy: 0.4832\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6652 - accuracy: 0.4746 - val_loss: 1.6501 - val_accuracy: 0.4879\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5697 - accuracy: 0.5066 - val_loss: 1.6320 - val_accuracy: 0.4960\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4856 - accuracy: 0.5239 - val_loss: 1.6201 - val_accuracy: 0.5010\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4141 - accuracy: 0.5473 - val_loss: 1.6012 - val_accuracy: 0.5124\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3358 - accuracy: 0.5705 - val_loss: 1.6268 - val_accuracy: 0.5097\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2888 - accuracy: 0.5851 - val_loss: 1.5847 - val_accuracy: 0.5180\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2165 - accuracy: 0.6044 - val_loss: 1.6150 - val_accuracy: 0.5204\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1758 - accuracy: 0.6158 - val_loss: 1.5986 - val_accuracy: 0.5204\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1160 - accuracy: 0.6304 - val_loss: 1.6471 - val_accuracy: 0.5152\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.0685 - accuracy: 0.6473 - val_loss: 1.6914 - val_accuracy: 0.5143\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0472 - accuracy: 0.6543 - val_loss: 1.6746 - val_accuracy: 0.5218\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0080 - accuracy: 0.6659 - val_loss: 1.6724 - val_accuracy: 0.5196\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.9611 - accuracy: 0.6813 - val_loss: 1.7054 - val_accuracy: 0.5148\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.9384 - accuracy: 0.6881 - val_loss: 1.6931 - val_accuracy: 0.5199\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.9157 - accuracy: 0.6948 - val_loss: 1.7338 - val_accuracy: 0.5256\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8790 - accuracy: 0.7049 - val_loss: 1.7620 - val_accuracy: 0.5183\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8611 - accuracy: 0.7137 - val_loss: 1.7686 - val_accuracy: 0.5236\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8430 - accuracy: 0.7168 - val_loss: 1.7584 - val_accuracy: 0.5185\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.8224 - accuracy: 0.7236 - val_loss: 1.8038 - val_accuracy: 0.5129\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7991 - accuracy: 0.7305 - val_loss: 1.7840 - val_accuracy: 0.5195\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7850 - accuracy: 0.7336 - val_loss: 1.8105 - val_accuracy: 0.5223\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7671 - accuracy: 0.7410 - val_loss: 1.8225 - val_accuracy: 0.5160\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7546 - accuracy: 0.7438 - val_loss: 1.8334 - val_accuracy: 0.5190\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7411 - accuracy: 0.7510 - val_loss: 1.7702 - val_accuracy: 0.5186\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7245 - accuracy: 0.7557 - val_loss: 1.8527 - val_accuracy: 0.5186\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.7050 - accuracy: 0.7609 - val_loss: 1.8651 - val_accuracy: 0.5229\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6938 - accuracy: 0.7653 - val_loss: 1.9122 - val_accuracy: 0.5170\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6873 - accuracy: 0.7690 - val_loss: 1.9445 - val_accuracy: 0.5189\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6688 - accuracy: 0.7750 - val_loss: 1.9273 - val_accuracy: 0.5245\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6657 - accuracy: 0.7756 - val_loss: 1.9129 - val_accuracy: 0.5124\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6487 - accuracy: 0.7821 - val_loss: 1.9742 - val_accuracy: 0.5188\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6404 - accuracy: 0.7847 - val_loss: 1.9553 - val_accuracy: 0.5179\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6379 - accuracy: 0.7840 - val_loss: 1.9197 - val_accuracy: 0.5236\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6279 - accuracy: 0.7877 - val_loss: 1.9505 - val_accuracy: 0.5160\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6161 - accuracy: 0.7942 - val_loss: 2.0460 - val_accuracy: 0.5240\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6053 - accuracy: 0.7976 - val_loss: 1.9562 - val_accuracy: 0.5220\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6000 - accuracy: 0.7968 - val_loss: 1.9254 - val_accuracy: 0.5212\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.5981 - accuracy: 0.7989 - val_loss: 2.0189 - val_accuracy: 0.5275\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.5897 - accuracy: 0.8006 - val_loss: 2.0079 - val_accuracy: 0.5204\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.5805 - accuracy: 0.8052 - val_loss: 1.9755 - val_accuracy: 0.5167\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.5740 - accuracy: 0.8073 - val_loss: 2.0434 - val_accuracy: 0.5206\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5652 - accuracy: 0.8104 - val_loss: 1.9990 - val_accuracy: 0.5241\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.5569 - accuracy: 0.8125 - val_loss: 2.0866 - val_accuracy: 0.5238\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.5446 - accuracy: 0.8174 - val_loss: 2.0223 - val_accuracy: 0.5220\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.5484 - accuracy: 0.8173 - val_loss: 2.0063 - val_accuracy: 0.5185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: a016692e8edd941c470814ec1497be8f</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5274999737739563</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_units: 256</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-first_layer_filters: 16</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-fourth_layer_filters: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-num_filters: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-second_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-third_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.6230 - accuracy: 0.1843 - val_loss: 2.3789 - val_accuracy: 0.2640\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 2.3334 - accuracy: 0.2818 - val_loss: 2.0967 - val_accuracy: 0.3510\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 2.1961 - accuracy: 0.3223 - val_loss: 1.9811 - val_accuracy: 0.3911\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 2.0918 - accuracy: 0.3542 - val_loss: 1.9048 - val_accuracy: 0.4131\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 2.0004 - accuracy: 0.3802 - val_loss: 1.8373 - val_accuracy: 0.4287\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.9361 - accuracy: 0.3958 - val_loss: 1.7757 - val_accuracy: 0.4477\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.8763 - accuracy: 0.4126 - val_loss: 1.7519 - val_accuracy: 0.4526\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.8148 - accuracy: 0.4313 - val_loss: 1.7251 - val_accuracy: 0.4621\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.7753 - accuracy: 0.4411 - val_loss: 1.6941 - val_accuracy: 0.4723\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.7291 - accuracy: 0.4534 - val_loss: 1.6714 - val_accuracy: 0.4831\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.6928 - accuracy: 0.4644 - val_loss: 1.6730 - val_accuracy: 0.4767\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.6590 - accuracy: 0.4737 - val_loss: 1.6664 - val_accuracy: 0.4866\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.6349 - accuracy: 0.4776 - val_loss: 1.6382 - val_accuracy: 0.4893\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.5960 - accuracy: 0.4889 - val_loss: 1.6606 - val_accuracy: 0.4893\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.5652 - accuracy: 0.4971 - val_loss: 1.5930 - val_accuracy: 0.5051\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.5408 - accuracy: 0.5041 - val_loss: 1.6309 - val_accuracy: 0.4936\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.5170 - accuracy: 0.5104 - val_loss: 1.6418 - val_accuracy: 0.4940\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.4964 - accuracy: 0.5161 - val_loss: 1.6330 - val_accuracy: 0.4969\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.4695 - accuracy: 0.5240 - val_loss: 1.5938 - val_accuracy: 0.5067\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.4573 - accuracy: 0.5286 - val_loss: 1.6322 - val_accuracy: 0.4947\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4359 - accuracy: 0.5344 - val_loss: 1.5751 - val_accuracy: 0.5120\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4037 - accuracy: 0.5430 - val_loss: 1.5714 - val_accuracy: 0.5186\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3893 - accuracy: 0.5445 - val_loss: 1.5963 - val_accuracy: 0.5101\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.3754 - accuracy: 0.5506 - val_loss: 1.5860 - val_accuracy: 0.5132\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.3530 - accuracy: 0.5569 - val_loss: 1.5754 - val_accuracy: 0.5175\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.3440 - accuracy: 0.5594 - val_loss: 1.5971 - val_accuracy: 0.5119\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.3314 - accuracy: 0.5637 - val_loss: 1.5793 - val_accuracy: 0.5248\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.3148 - accuracy: 0.5679 - val_loss: 1.5841 - val_accuracy: 0.5245\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.3068 - accuracy: 0.5712 - val_loss: 1.5830 - val_accuracy: 0.5256\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.2868 - accuracy: 0.5737 - val_loss: 1.6083 - val_accuracy: 0.5131\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.2805 - accuracy: 0.5779 - val_loss: 1.5871 - val_accuracy: 0.5163\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.2674 - accuracy: 0.5797 - val_loss: 1.6030 - val_accuracy: 0.5142\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.2484 - accuracy: 0.5878 - val_loss: 1.6371 - val_accuracy: 0.5123\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.2498 - accuracy: 0.5874 - val_loss: 1.6254 - val_accuracy: 0.5141\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.2445 - accuracy: 0.5871 - val_loss: 1.5772 - val_accuracy: 0.5248\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.2248 - accuracy: 0.5925 - val_loss: 1.6118 - val_accuracy: 0.5193\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.2176 - accuracy: 0.5984 - val_loss: 1.6001 - val_accuracy: 0.5169\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.2129 - accuracy: 0.5980 - val_loss: 1.6057 - val_accuracy: 0.5210\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1907 - accuracy: 0.6045 - val_loss: 1.6126 - val_accuracy: 0.5235\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1890 - accuracy: 0.6050 - val_loss: 1.6035 - val_accuracy: 0.5235\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1832 - accuracy: 0.6058 - val_loss: 1.6379 - val_accuracy: 0.5229\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1721 - accuracy: 0.6078 - val_loss: 1.6415 - val_accuracy: 0.5251\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1678 - accuracy: 0.6124 - val_loss: 1.6312 - val_accuracy: 0.5254\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1630 - accuracy: 0.6136 - val_loss: 1.6215 - val_accuracy: 0.5265\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1529 - accuracy: 0.6164 - val_loss: 1.6333 - val_accuracy: 0.5236\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1477 - accuracy: 0.6189 - val_loss: 1.6098 - val_accuracy: 0.5291\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1436 - accuracy: 0.6173 - val_loss: 1.6181 - val_accuracy: 0.5207\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1329 - accuracy: 0.6231 - val_loss: 1.6269 - val_accuracy: 0.5218\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1221 - accuracy: 0.6245 - val_loss: 1.6429 - val_accuracy: 0.5203\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.1194 - accuracy: 0.6261 - val_loss: 1.6139 - val_accuracy: 0.5245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: aeee0c2fd2f93c0f8643110913abdd31</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5291000008583069</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_units: 128</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-first_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-fourth_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-num_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-second_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-third_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.6610 - accuracy: 0.1752 - val_loss: 2.3902 - val_accuracy: 0.2807\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.3887 - accuracy: 0.2600 - val_loss: 2.1634 - val_accuracy: 0.3476\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.2529 - accuracy: 0.3008 - val_loss: 2.0464 - val_accuracy: 0.3732\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.1618 - accuracy: 0.3284 - val_loss: 1.9788 - val_accuracy: 0.3924\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.0944 - accuracy: 0.3477 - val_loss: 1.9436 - val_accuracy: 0.4062\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.0254 - accuracy: 0.3676 - val_loss: 1.8495 - val_accuracy: 0.4307\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.9664 - accuracy: 0.3846 - val_loss: 1.8137 - val_accuracy: 0.4419\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.9087 - accuracy: 0.4009 - val_loss: 1.7265 - val_accuracy: 0.4611\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.8674 - accuracy: 0.4137 - val_loss: 1.7320 - val_accuracy: 0.4629\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.8160 - accuracy: 0.4261 - val_loss: 1.6715 - val_accuracy: 0.4830\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.7784 - accuracy: 0.4354 - val_loss: 1.6520 - val_accuracy: 0.4889\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.7539 - accuracy: 0.4419 - val_loss: 1.6384 - val_accuracy: 0.4854\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.7293 - accuracy: 0.4473 - val_loss: 1.6282 - val_accuracy: 0.4912\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6956 - accuracy: 0.4597 - val_loss: 1.6128 - val_accuracy: 0.4998\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6636 - accuracy: 0.4662 - val_loss: 1.5905 - val_accuracy: 0.5024\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6464 - accuracy: 0.4711 - val_loss: 1.5859 - val_accuracy: 0.5098\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6272 - accuracy: 0.4764 - val_loss: 1.5607 - val_accuracy: 0.5149\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6004 - accuracy: 0.4839 - val_loss: 1.5919 - val_accuracy: 0.5065\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5864 - accuracy: 0.4879 - val_loss: 1.5605 - val_accuracy: 0.5175\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5685 - accuracy: 0.4912 - val_loss: 1.5432 - val_accuracy: 0.5230\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5576 - accuracy: 0.4948 - val_loss: 1.5470 - val_accuracy: 0.5180\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5295 - accuracy: 0.5043 - val_loss: 1.5592 - val_accuracy: 0.5143\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5075 - accuracy: 0.5041 - val_loss: 1.5468 - val_accuracy: 0.5202\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5008 - accuracy: 0.5131 - val_loss: 1.5289 - val_accuracy: 0.5262\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4828 - accuracy: 0.5170 - val_loss: 1.5165 - val_accuracy: 0.5263\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4698 - accuracy: 0.5168 - val_loss: 1.5555 - val_accuracy: 0.5155\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4488 - accuracy: 0.5267 - val_loss: 1.5326 - val_accuracy: 0.5241\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4410 - accuracy: 0.5290 - val_loss: 1.5360 - val_accuracy: 0.5245\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4347 - accuracy: 0.5303 - val_loss: 1.5518 - val_accuracy: 0.5215\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4134 - accuracy: 0.5404 - val_loss: 1.5431 - val_accuracy: 0.5223\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4037 - accuracy: 0.5373 - val_loss: 1.5004 - val_accuracy: 0.5343\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3894 - accuracy: 0.5446 - val_loss: 1.5492 - val_accuracy: 0.5278\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3874 - accuracy: 0.5424 - val_loss: 1.5471 - val_accuracy: 0.5293\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3770 - accuracy: 0.5457 - val_loss: 1.5242 - val_accuracy: 0.5301\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3559 - accuracy: 0.5520 - val_loss: 1.5182 - val_accuracy: 0.5367\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3529 - accuracy: 0.5547 - val_loss: 1.5270 - val_accuracy: 0.5369\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3379 - accuracy: 0.5560 - val_loss: 1.5624 - val_accuracy: 0.5253\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3383 - accuracy: 0.5568 - val_loss: 1.5034 - val_accuracy: 0.5333\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3228 - accuracy: 0.5621 - val_loss: 1.5243 - val_accuracy: 0.5391\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3173 - accuracy: 0.5652 - val_loss: 1.5281 - val_accuracy: 0.5364\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3107 - accuracy: 0.5642 - val_loss: 1.5078 - val_accuracy: 0.5362\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3027 - accuracy: 0.5684 - val_loss: 1.5183 - val_accuracy: 0.5420\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2946 - accuracy: 0.5700 - val_loss: 1.5424 - val_accuracy: 0.5341\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2913 - accuracy: 0.5722 - val_loss: 1.5410 - val_accuracy: 0.5408\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2900 - accuracy: 0.5725 - val_loss: 1.5185 - val_accuracy: 0.5374\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2744 - accuracy: 0.5738 - val_loss: 1.5183 - val_accuracy: 0.5372\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2668 - accuracy: 0.5755 - val_loss: 1.5395 - val_accuracy: 0.5403\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2642 - accuracy: 0.5761 - val_loss: 1.5228 - val_accuracy: 0.5417\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2551 - accuracy: 0.5810 - val_loss: 1.5321 - val_accuracy: 0.5402\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2481 - accuracy: 0.5822 - val_loss: 1.5262 - val_accuracy: 0.5404\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: f542c217100fae48f7292b065584d85a</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.5419999957084656</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_units: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-first_layer_filters: 16</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-fourth_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-num_filters: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-second_layer_filters: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-third_layer_filters: 128</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               2097280   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                2580      \n",
            "=================================================================\n",
            "Total params: 2,165,428\n",
            "Trainable params: 2,165,428\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "{'num_filters': 32, 'first_layer_filters': 32, 'second_layer_filters': 32, 'third_layer_filters': 64, 'fourth_layer_filters': 64, 'dense_units': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYW1LcBHBNc8",
        "colab_type": "text"
      },
      "source": [
        "##Part 3 - Predicting fine labels using the existing model and transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFKVUlxbOuCc",
        "colab_type": "text"
      },
      "source": [
        "###Predicting fine labels using the existing model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCVMsjRWAQn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4b16362e-3b79-49b1-b402-94837c4b74ee"
      },
      "source": [
        "# Download CIFAR 100 with all 100 labels \n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "128M16KlHf-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1dd5cd58-5b60-41b6-c16f-374da6544ea6"
      },
      "source": [
        "#One hot encoding the target variables and standardising x inputs so they're\n",
        "#between 0 and 1\n",
        "y_input = tf.keras.utils.to_categorical(y_train)\n",
        "x_input = (x_train / 255.0)\n",
        "\n",
        "#Using test set as validation for simplicity\n",
        "y_valid = tf.keras.utils.to_categorical(y_test)\n",
        "x_valid = (x_test / 255.0)\n",
        "\n",
        "#Checking shape\n",
        "print('y_input shape ' + str(y_input.shape))\n",
        "print('x_input shape ' + str(x_input.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_input shape (50000, 100)\n",
            "x_input shape (50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFh7XaS_HVbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fine_labels = [\n",
        "'apple',\n",
        "'aquarium_fish',\n",
        "'baby',\n",
        "'bear',\n",
        "'beaver',\n",
        "'bed',\n",
        "'bee',\n",
        "'beetle',\n",
        "'bicycle',\n",
        "'bottle',\n",
        "'bowl',\n",
        "'boy',\n",
        "'bridge',\n",
        "'bus',\n",
        "'butterfly',\n",
        "'camel',\n",
        "'can',\n",
        "'castle',\n",
        "'caterpillar',\n",
        "'cattle',\n",
        "'chair',\n",
        "'chimpanzee',\n",
        "'clock',\n",
        "'cloud',\n",
        "'cockroach',\n",
        "'couch',\n",
        "'crab',\n",
        "'crocodile',\n",
        "'cup',\n",
        "'dinosaur',\n",
        "'dolphin',\n",
        "'elephant',\n",
        "'flatfish',\n",
        "'forest',\n",
        "'fox',\n",
        "'girl',\n",
        "'hamster',\n",
        "'house',\n",
        "'kangaroo',\n",
        "'computer_keyboard',\n",
        "'lamp',\n",
        "'lawn_mower',\n",
        "'leopard',\n",
        "'lion',\n",
        "'lizard',\n",
        "'lobster',\n",
        "'man',\n",
        "'maple_tree',\n",
        "'motorcycle',\n",
        "'mountain',\n",
        "'mouse',\n",
        "'mushroom',\n",
        "'oak_tree',\n",
        "'orange',\n",
        "'orchid',\n",
        "'otter',\n",
        "'palm_tree',\n",
        "'pear',\n",
        "'pickup_truck',\n",
        "'pine_tree',\n",
        "'plain',\n",
        "'plate',\n",
        "'poppy',\n",
        "'porcupine',\n",
        "'possum',\n",
        "'rabbit',\n",
        "'raccoon',\n",
        "'ray',\n",
        "'road',\n",
        "'rocket',\n",
        "'rose',\n",
        "'sea',\n",
        "'seal',\n",
        "'shark',\n",
        "'shrew',\n",
        "'skunk',\n",
        "'skyscraper',\n",
        "'snail',\n",
        "'snake',\n",
        "'spider',\n",
        "'squirrel',\n",
        "'streetcar',\n",
        "'sunflower',\n",
        "'sweet_pepper',\n",
        "'table',\n",
        "'tank',\n",
        "'telephone',\n",
        "'television',\n",
        "'tiger',\n",
        "'tractor',\n",
        "'train',\n",
        "'trout',\n",
        "'tulip',\n",
        "'turtle',\n",
        "'wardrobe',\n",
        "'whale',\n",
        "'willow_tree',\n",
        "'wolf',\n",
        "'woman',\n",
        "'worm',\n",
        "]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug7_BinEHm9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "f33afce4-6433-488d-c5be-09ff58baa2eb"
      },
      "source": [
        "#Example image fine\n",
        "i=0\n",
        "label = y_train[i]\n",
        "image = x_train[i]\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.grid(False)\n",
        "plt.title((fine_labels[int(label)]))\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_LAPP0PHq23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f496f353-3332-4522-91e5-017840db3f5e"
      },
      "source": [
        "#Setting up logging files\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#Creating layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same',\n",
        "  input_shape=( 32, 32, 3)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same',\n",
        "  input_shape=( 32, 32, 3)))\n",
        "\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same'))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),\n",
        "  activation=tf.nn.relu,padding='same'))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=128, activation=tf.nn.relu))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=100,activation=tf.nn.softmax))\n",
        "\n",
        "#Compiling model using an Adam optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "#Recording model checkpoints\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "#Logging to tensorboard\n",
        "tb_log = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "#Creating early stopping where validation loss does not improve\n",
        "#early_loss = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "#Save best model weights based on validation accuracy\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "callbacks = [tb_log,\n",
        "             #early_loss,\n",
        "             mcp_save]\n",
        "\n",
        "#Fitting model\n",
        "model.fit(x_input, y_input, epochs=100,\n",
        "  batch_size=64,\n",
        "  callbacks=callbacks,\n",
        "  validation_data=(x_valid, y_valid))\n",
        "\n",
        "#Returning best weights\n",
        "model.load_weights(filepath = '.mdl_wts.hdf5')\n",
        "\n",
        "#Recording test accuracy\n",
        "predictions = model.predict(x_valid)\n",
        "y_pred = np.argmax(predictions,axis=-1)\n",
        "print('test accuracy: ', np.sum(y_pred==y_test[:,0])/len(y_test))\n",
        "## test accuracy: 0.3846"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 4.2913 - accuracy: 0.0448 - val_loss: 3.8075 - val_accuracy: 0.1242\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 3.8312 - accuracy: 0.1041 - val_loss: 3.4589 - val_accuracy: 0.1956\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 3.5973 - accuracy: 0.1404 - val_loss: 3.2249 - val_accuracy: 0.2289\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 3.4442 - accuracy: 0.1663 - val_loss: 3.1484 - val_accuracy: 0.2494\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 3.3273 - accuracy: 0.1841 - val_loss: 2.9835 - val_accuracy: 0.2680\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 3.2189 - accuracy: 0.2028 - val_loss: 2.8830 - val_accuracy: 0.2814\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 3.1384 - accuracy: 0.2182 - val_loss: 2.8232 - val_accuracy: 0.2958\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 3.0646 - accuracy: 0.2291 - val_loss: 2.7591 - val_accuracy: 0.3118\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.9989 - accuracy: 0.2404 - val_loss: 2.7302 - val_accuracy: 0.3138\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.9383 - accuracy: 0.2529 - val_loss: 2.7196 - val_accuracy: 0.3137\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.8750 - accuracy: 0.2655 - val_loss: 2.6674 - val_accuracy: 0.3257\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.8119 - accuracy: 0.2770 - val_loss: 2.6126 - val_accuracy: 0.3390\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.7641 - accuracy: 0.2856 - val_loss: 2.6451 - val_accuracy: 0.3295\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.7024 - accuracy: 0.2963 - val_loss: 2.5875 - val_accuracy: 0.3489\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.6602 - accuracy: 0.3031 - val_loss: 2.6155 - val_accuracy: 0.3353\n",
            "Epoch 16/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.6092 - accuracy: 0.3119 - val_loss: 2.5512 - val_accuracy: 0.3504\n",
            "Epoch 17/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.5753 - accuracy: 0.3217 - val_loss: 2.5530 - val_accuracy: 0.3512\n",
            "Epoch 18/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.5352 - accuracy: 0.3252 - val_loss: 2.5675 - val_accuracy: 0.3505\n",
            "Epoch 19/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.5032 - accuracy: 0.3313 - val_loss: 2.5629 - val_accuracy: 0.3530\n",
            "Epoch 20/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.4513 - accuracy: 0.3421 - val_loss: 2.5493 - val_accuracy: 0.3563\n",
            "Epoch 21/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.4232 - accuracy: 0.3484 - val_loss: 2.5371 - val_accuracy: 0.3596\n",
            "Epoch 22/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.3759 - accuracy: 0.3589 - val_loss: 2.5315 - val_accuracy: 0.3558\n",
            "Epoch 23/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.3402 - accuracy: 0.3686 - val_loss: 2.5058 - val_accuracy: 0.3669\n",
            "Epoch 24/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.3127 - accuracy: 0.3693 - val_loss: 2.5192 - val_accuracy: 0.3720\n",
            "Epoch 25/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.2784 - accuracy: 0.3801 - val_loss: 2.5328 - val_accuracy: 0.3659\n",
            "Epoch 26/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.2442 - accuracy: 0.3870 - val_loss: 2.5083 - val_accuracy: 0.3672\n",
            "Epoch 27/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.2086 - accuracy: 0.3928 - val_loss: 2.5153 - val_accuracy: 0.3706\n",
            "Epoch 28/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.1846 - accuracy: 0.3993 - val_loss: 2.5223 - val_accuracy: 0.3736\n",
            "Epoch 29/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.1617 - accuracy: 0.4055 - val_loss: 2.5181 - val_accuracy: 0.3680\n",
            "Epoch 30/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.1233 - accuracy: 0.4139 - val_loss: 2.5176 - val_accuracy: 0.3712\n",
            "Epoch 31/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.0995 - accuracy: 0.4169 - val_loss: 2.5456 - val_accuracy: 0.3692\n",
            "Epoch 32/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.0854 - accuracy: 0.4193 - val_loss: 2.5163 - val_accuracy: 0.3742\n",
            "Epoch 33/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 2.0535 - accuracy: 0.4261 - val_loss: 2.5614 - val_accuracy: 0.3701\n",
            "Epoch 34/100\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 2.0364 - accuracy: 0.4305 - val_loss: 2.5436 - val_accuracy: 0.3722\n",
            "Epoch 35/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.9938 - accuracy: 0.4389 - val_loss: 2.5570 - val_accuracy: 0.3730\n",
            "Epoch 36/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.9909 - accuracy: 0.4396 - val_loss: 2.5553 - val_accuracy: 0.3715\n",
            "Epoch 37/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.9581 - accuracy: 0.4479 - val_loss: 2.5637 - val_accuracy: 0.3693\n",
            "Epoch 38/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.9477 - accuracy: 0.4507 - val_loss: 2.5656 - val_accuracy: 0.3726\n",
            "Epoch 39/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.9184 - accuracy: 0.4565 - val_loss: 2.5576 - val_accuracy: 0.3723\n",
            "Epoch 40/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.8910 - accuracy: 0.4632 - val_loss: 2.5488 - val_accuracy: 0.3716\n",
            "Epoch 41/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.8807 - accuracy: 0.4620 - val_loss: 2.5934 - val_accuracy: 0.3775\n",
            "Epoch 42/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.8764 - accuracy: 0.4647 - val_loss: 2.5754 - val_accuracy: 0.3748\n",
            "Epoch 43/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.8431 - accuracy: 0.4764 - val_loss: 2.5940 - val_accuracy: 0.3732\n",
            "Epoch 44/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.8211 - accuracy: 0.4821 - val_loss: 2.5737 - val_accuracy: 0.3748\n",
            "Epoch 45/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.8185 - accuracy: 0.4776 - val_loss: 2.5838 - val_accuracy: 0.3784\n",
            "Epoch 46/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.7846 - accuracy: 0.4881 - val_loss: 2.6108 - val_accuracy: 0.3762\n",
            "Epoch 47/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.7771 - accuracy: 0.4896 - val_loss: 2.6177 - val_accuracy: 0.3753\n",
            "Epoch 48/100\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.7614 - accuracy: 0.4950 - val_loss: 2.6296 - val_accuracy: 0.3770\n",
            "Epoch 49/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.7327 - accuracy: 0.5009 - val_loss: 2.6512 - val_accuracy: 0.3754\n",
            "Epoch 50/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.7298 - accuracy: 0.5000 - val_loss: 2.6247 - val_accuracy: 0.3750\n",
            "Epoch 51/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.7066 - accuracy: 0.5090 - val_loss: 2.6159 - val_accuracy: 0.3740\n",
            "Epoch 52/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6971 - accuracy: 0.5129 - val_loss: 2.6435 - val_accuracy: 0.3690\n",
            "Epoch 53/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6767 - accuracy: 0.5157 - val_loss: 2.6892 - val_accuracy: 0.3685\n",
            "Epoch 54/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6723 - accuracy: 0.5146 - val_loss: 2.6751 - val_accuracy: 0.3713\n",
            "Epoch 55/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6540 - accuracy: 0.5215 - val_loss: 2.7323 - val_accuracy: 0.3709\n",
            "Epoch 56/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6345 - accuracy: 0.5250 - val_loss: 2.6776 - val_accuracy: 0.3764\n",
            "Epoch 57/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6128 - accuracy: 0.5315 - val_loss: 2.6853 - val_accuracy: 0.3782\n",
            "Epoch 58/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.6074 - accuracy: 0.5329 - val_loss: 2.7184 - val_accuracy: 0.3718\n",
            "Epoch 59/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5849 - accuracy: 0.5403 - val_loss: 2.7038 - val_accuracy: 0.3711\n",
            "Epoch 60/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5908 - accuracy: 0.5383 - val_loss: 2.6815 - val_accuracy: 0.3770\n",
            "Epoch 61/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.5605 - accuracy: 0.5445 - val_loss: 2.7228 - val_accuracy: 0.3799\n",
            "Epoch 62/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5561 - accuracy: 0.5469 - val_loss: 2.7014 - val_accuracy: 0.3701\n",
            "Epoch 63/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5454 - accuracy: 0.5487 - val_loss: 2.7380 - val_accuracy: 0.3753\n",
            "Epoch 64/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5236 - accuracy: 0.5556 - val_loss: 2.6989 - val_accuracy: 0.3745\n",
            "Epoch 65/100\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.5152 - accuracy: 0.5577 - val_loss: 2.7198 - val_accuracy: 0.3713\n",
            "Epoch 66/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.5115 - accuracy: 0.5576 - val_loss: 2.7449 - val_accuracy: 0.3775\n",
            "Epoch 67/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4936 - accuracy: 0.5629 - val_loss: 2.7617 - val_accuracy: 0.3652\n",
            "Epoch 68/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4889 - accuracy: 0.5651 - val_loss: 2.7286 - val_accuracy: 0.3750\n",
            "Epoch 69/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4863 - accuracy: 0.5641 - val_loss: 2.7993 - val_accuracy: 0.3718\n",
            "Epoch 70/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4714 - accuracy: 0.5679 - val_loss: 2.7891 - val_accuracy: 0.3753\n",
            "Epoch 71/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4656 - accuracy: 0.5701 - val_loss: 2.8099 - val_accuracy: 0.3776\n",
            "Epoch 72/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4437 - accuracy: 0.5768 - val_loss: 2.7460 - val_accuracy: 0.3769\n",
            "Epoch 73/100\n",
            "782/782 [==============================] - 5s 7ms/step - loss: 1.4393 - accuracy: 0.5762 - val_loss: 2.7320 - val_accuracy: 0.3751\n",
            "Epoch 74/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4247 - accuracy: 0.5802 - val_loss: 2.8264 - val_accuracy: 0.3707\n",
            "Epoch 75/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4273 - accuracy: 0.5789 - val_loss: 2.8007 - val_accuracy: 0.3756\n",
            "Epoch 76/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4206 - accuracy: 0.5820 - val_loss: 2.8277 - val_accuracy: 0.3782\n",
            "Epoch 77/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.4018 - accuracy: 0.5876 - val_loss: 2.8368 - val_accuracy: 0.3763\n",
            "Epoch 78/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3933 - accuracy: 0.5879 - val_loss: 2.7911 - val_accuracy: 0.3782\n",
            "Epoch 79/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3889 - accuracy: 0.5915 - val_loss: 2.7697 - val_accuracy: 0.3802\n",
            "Epoch 80/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3814 - accuracy: 0.5921 - val_loss: 2.7481 - val_accuracy: 0.3774\n",
            "Epoch 81/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3676 - accuracy: 0.5965 - val_loss: 2.7964 - val_accuracy: 0.3765\n",
            "Epoch 82/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3594 - accuracy: 0.5979 - val_loss: 2.7789 - val_accuracy: 0.3781\n",
            "Epoch 83/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3635 - accuracy: 0.5965 - val_loss: 2.7589 - val_accuracy: 0.3752\n",
            "Epoch 84/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3475 - accuracy: 0.6021 - val_loss: 2.8194 - val_accuracy: 0.3770\n",
            "Epoch 85/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3363 - accuracy: 0.6068 - val_loss: 2.8191 - val_accuracy: 0.3766\n",
            "Epoch 86/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3282 - accuracy: 0.6055 - val_loss: 2.8163 - val_accuracy: 0.3762\n",
            "Epoch 87/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3195 - accuracy: 0.6098 - val_loss: 2.8452 - val_accuracy: 0.3811\n",
            "Epoch 88/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3196 - accuracy: 0.6091 - val_loss: 2.8241 - val_accuracy: 0.3788\n",
            "Epoch 89/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3008 - accuracy: 0.6116 - val_loss: 2.8771 - val_accuracy: 0.3758\n",
            "Epoch 90/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2974 - accuracy: 0.6153 - val_loss: 2.8274 - val_accuracy: 0.3846\n",
            "Epoch 91/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.3052 - accuracy: 0.6128 - val_loss: 2.8475 - val_accuracy: 0.3799\n",
            "Epoch 92/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2896 - accuracy: 0.6174 - val_loss: 2.8277 - val_accuracy: 0.3780\n",
            "Epoch 93/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2893 - accuracy: 0.6177 - val_loss: 2.8496 - val_accuracy: 0.3769\n",
            "Epoch 94/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2875 - accuracy: 0.6166 - val_loss: 2.8595 - val_accuracy: 0.3790\n",
            "Epoch 95/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2671 - accuracy: 0.6240 - val_loss: 2.8705 - val_accuracy: 0.3751\n",
            "Epoch 96/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2573 - accuracy: 0.6262 - val_loss: 2.8537 - val_accuracy: 0.3777\n",
            "Epoch 97/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2487 - accuracy: 0.6284 - val_loss: 2.8315 - val_accuracy: 0.3797\n",
            "Epoch 98/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2523 - accuracy: 0.6255 - val_loss: 2.8980 - val_accuracy: 0.3801\n",
            "Epoch 99/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2436 - accuracy: 0.6289 - val_loss: 2.8975 - val_accuracy: 0.3762\n",
            "Epoch 100/100\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.2418 - accuracy: 0.6292 - val_loss: 2.9485 - val_accuracy: 0.3730\n",
            "test accuracy:  0.3846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnkURMX6IQRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Examining loss on TensorBoard\n",
        "%tensorboard --logdir logs/scalars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBPvRFSKO4Pv",
        "colab_type": "text"
      },
      "source": [
        "###Predicting fine labels using transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aysDG2vFO3Nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import VGG16 network\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Model"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Izo2g-Qj8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reading in the model without the top layer and loading weights from imagenet\n",
        "base_model = VGG16(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=y_train.shape[1])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2sOdD1RWH0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting up logging files\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#Adding additional layers so that it can classify the CIFAR data\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(units=100,activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSGuzVx8Q1zb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5fcac454-9227-4220-b84b-8ce6f7aba461"
      },
      "source": [
        "#Compiling model using an Adam optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "#Recording model checkpoints\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "#Logging to tensorboard\n",
        "tb_log = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "#Creating early stopping where validation loss does not improve\n",
        "#early_loss = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "#Save best model weights based on validation accuracy\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "callbacks = [tb_log,\n",
        "             #early_loss,\n",
        "             mcp_save]\n",
        "\n",
        "#Fitting model\n",
        "model.fit(x_input, y_input, epochs=100,\n",
        "  batch_size=64,\n",
        "  callbacks=callbacks,\n",
        "  validation_data=(x_valid, y_valid))\n",
        "\n",
        "#Returning best weights\n",
        "model.load_weights(filepath = '.mdl_wts.hdf5')\n",
        "\n",
        "#Recording test accuracy\n",
        "predictions = model.predict(x_valid)\n",
        "y_pred = np.argmax(predictions,axis=-1)\n",
        "print('test accuracy: ', np.sum(y_pred==y_test[:,0])/len(y_test))\n",
        "## test accuracy: 0.1546"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 4.2909 - accuracy: 0.0920 - val_loss: 4.1969 - val_accuracy: 0.1073\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 4.0131 - accuracy: 0.1332 - val_loss: 4.1575 - val_accuracy: 0.1145\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.9265 - accuracy: 0.1461 - val_loss: 4.1031 - val_accuracy: 0.1298\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.8766 - accuracy: 0.1558 - val_loss: 4.0464 - val_accuracy: 0.1312\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.8283 - accuracy: 0.1652 - val_loss: 4.0563 - val_accuracy: 0.1314\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.8092 - accuracy: 0.1664 - val_loss: 4.1223 - val_accuracy: 0.1377\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.7645 - accuracy: 0.1752 - val_loss: 4.1384 - val_accuracy: 0.1364\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.7502 - accuracy: 0.1791 - val_loss: 4.2274 - val_accuracy: 0.1330\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.7055 - accuracy: 0.1839 - val_loss: 4.1628 - val_accuracy: 0.1281\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.6871 - accuracy: 0.1867 - val_loss: 4.1808 - val_accuracy: 0.1435\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.6638 - accuracy: 0.1911 - val_loss: 4.1591 - val_accuracy: 0.1446\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.6461 - accuracy: 0.1958 - val_loss: 4.0179 - val_accuracy: 0.1476\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.6308 - accuracy: 0.1964 - val_loss: 4.1270 - val_accuracy: 0.1408\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.6067 - accuracy: 0.2003 - val_loss: 4.1684 - val_accuracy: 0.1354\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.5888 - accuracy: 0.2056 - val_loss: 4.1616 - val_accuracy: 0.1404\n",
            "Epoch 16/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.5819 - accuracy: 0.2047 - val_loss: 4.1472 - val_accuracy: 0.1350\n",
            "Epoch 17/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.5489 - accuracy: 0.2102 - val_loss: 4.2042 - val_accuracy: 0.1424\n",
            "Epoch 18/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.5613 - accuracy: 0.2095 - val_loss: 4.1286 - val_accuracy: 0.1417\n",
            "Epoch 19/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.5327 - accuracy: 0.2136 - val_loss: 4.1140 - val_accuracy: 0.1438\n",
            "Epoch 20/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.5245 - accuracy: 0.2148 - val_loss: 4.1181 - val_accuracy: 0.1468\n",
            "Epoch 21/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.4954 - accuracy: 0.2217 - val_loss: 4.2384 - val_accuracy: 0.1406\n",
            "Epoch 22/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.4948 - accuracy: 0.2212 - val_loss: 4.1798 - val_accuracy: 0.1387\n",
            "Epoch 23/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.4750 - accuracy: 0.2234 - val_loss: 4.2496 - val_accuracy: 0.1421\n",
            "Epoch 24/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.4742 - accuracy: 0.2242 - val_loss: 4.2827 - val_accuracy: 0.1224\n",
            "Epoch 25/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.4608 - accuracy: 0.2270 - val_loss: 4.1558 - val_accuracy: 0.1437\n",
            "Epoch 26/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.4528 - accuracy: 0.2267 - val_loss: 4.1721 - val_accuracy: 0.1368\n",
            "Epoch 27/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.4360 - accuracy: 0.2297 - val_loss: 4.1663 - val_accuracy: 0.1424\n",
            "Epoch 28/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.4241 - accuracy: 0.2324 - val_loss: 4.4155 - val_accuracy: 0.1208\n",
            "Epoch 29/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.4209 - accuracy: 0.2314 - val_loss: 4.1573 - val_accuracy: 0.1436\n",
            "Epoch 30/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.4090 - accuracy: 0.2354 - val_loss: 4.1080 - val_accuracy: 0.1546\n",
            "Epoch 31/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.4046 - accuracy: 0.2367 - val_loss: 4.1013 - val_accuracy: 0.1522\n",
            "Epoch 32/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.3906 - accuracy: 0.2363 - val_loss: 4.2063 - val_accuracy: 0.1395\n",
            "Epoch 33/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.3742 - accuracy: 0.2418 - val_loss: 4.2649 - val_accuracy: 0.1345\n",
            "Epoch 34/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.3671 - accuracy: 0.2416 - val_loss: 4.1641 - val_accuracy: 0.1361\n",
            "Epoch 35/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.3566 - accuracy: 0.2426 - val_loss: 4.2305 - val_accuracy: 0.1347\n",
            "Epoch 36/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.3543 - accuracy: 0.2446 - val_loss: 4.1526 - val_accuracy: 0.1446\n",
            "Epoch 37/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.3639 - accuracy: 0.2420 - val_loss: 4.2631 - val_accuracy: 0.1363\n",
            "Epoch 38/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.3387 - accuracy: 0.2465 - val_loss: 4.1444 - val_accuracy: 0.1534\n",
            "Epoch 39/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.3260 - accuracy: 0.2493 - val_loss: 4.1623 - val_accuracy: 0.1531\n",
            "Epoch 40/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.3367 - accuracy: 0.2487 - val_loss: 4.1104 - val_accuracy: 0.1512\n",
            "Epoch 41/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.3162 - accuracy: 0.2498 - val_loss: 4.3222 - val_accuracy: 0.1275\n",
            "Epoch 42/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.3205 - accuracy: 0.2495 - val_loss: 4.1802 - val_accuracy: 0.1514\n",
            "Epoch 43/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.3071 - accuracy: 0.2519 - val_loss: 4.2824 - val_accuracy: 0.1331\n",
            "Epoch 44/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.3042 - accuracy: 0.2528 - val_loss: 4.2878 - val_accuracy: 0.1410\n",
            "Epoch 45/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2933 - accuracy: 0.2535 - val_loss: 4.2231 - val_accuracy: 0.1459\n",
            "Epoch 46/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2903 - accuracy: 0.2565 - val_loss: 4.2132 - val_accuracy: 0.1451\n",
            "Epoch 47/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2725 - accuracy: 0.2583 - val_loss: 4.2538 - val_accuracy: 0.1433\n",
            "Epoch 48/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2723 - accuracy: 0.2575 - val_loss: 4.3514 - val_accuracy: 0.1278\n",
            "Epoch 49/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2653 - accuracy: 0.2591 - val_loss: 4.3457 - val_accuracy: 0.1410\n",
            "Epoch 50/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2712 - accuracy: 0.2583 - val_loss: 4.1548 - val_accuracy: 0.1479\n",
            "Epoch 51/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2549 - accuracy: 0.2629 - val_loss: 4.1705 - val_accuracy: 0.1484\n",
            "Epoch 52/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2503 - accuracy: 0.2635 - val_loss: 4.2807 - val_accuracy: 0.1385\n",
            "Epoch 53/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2329 - accuracy: 0.2637 - val_loss: 4.1912 - val_accuracy: 0.1418\n",
            "Epoch 54/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2269 - accuracy: 0.2655 - val_loss: 4.1160 - val_accuracy: 0.1488\n",
            "Epoch 55/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2249 - accuracy: 0.2664 - val_loss: 4.2709 - val_accuracy: 0.1414\n",
            "Epoch 56/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2329 - accuracy: 0.2644 - val_loss: 4.3251 - val_accuracy: 0.1327\n",
            "Epoch 57/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2246 - accuracy: 0.2675 - val_loss: 4.3161 - val_accuracy: 0.1417\n",
            "Epoch 58/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2219 - accuracy: 0.2660 - val_loss: 4.3077 - val_accuracy: 0.1315\n",
            "Epoch 59/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2125 - accuracy: 0.2699 - val_loss: 4.3563 - val_accuracy: 0.1324\n",
            "Epoch 60/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2088 - accuracy: 0.2683 - val_loss: 4.2584 - val_accuracy: 0.1419\n",
            "Epoch 61/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1985 - accuracy: 0.2686 - val_loss: 4.2917 - val_accuracy: 0.1384\n",
            "Epoch 62/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.2008 - accuracy: 0.2710 - val_loss: 4.5181 - val_accuracy: 0.1213\n",
            "Epoch 63/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1890 - accuracy: 0.2728 - val_loss: 4.2591 - val_accuracy: 0.1506\n",
            "Epoch 64/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1787 - accuracy: 0.2728 - val_loss: 4.1859 - val_accuracy: 0.1486\n",
            "Epoch 65/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.1822 - accuracy: 0.2728 - val_loss: 4.2427 - val_accuracy: 0.1464\n",
            "Epoch 66/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1766 - accuracy: 0.2750 - val_loss: 4.4035 - val_accuracy: 0.1357\n",
            "Epoch 67/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1757 - accuracy: 0.2749 - val_loss: 4.3619 - val_accuracy: 0.1335\n",
            "Epoch 68/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1611 - accuracy: 0.2767 - val_loss: 4.3978 - val_accuracy: 0.1304\n",
            "Epoch 69/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.1539 - accuracy: 0.2776 - val_loss: 4.4402 - val_accuracy: 0.1272\n",
            "Epoch 70/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.1571 - accuracy: 0.2767 - val_loss: 4.3387 - val_accuracy: 0.1447\n",
            "Epoch 71/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1443 - accuracy: 0.2807 - val_loss: 4.2365 - val_accuracy: 0.1407\n",
            "Epoch 72/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1550 - accuracy: 0.2763 - val_loss: 4.4677 - val_accuracy: 0.1329\n",
            "Epoch 73/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1438 - accuracy: 0.2801 - val_loss: 4.4025 - val_accuracy: 0.1369\n",
            "Epoch 74/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1255 - accuracy: 0.2842 - val_loss: 4.3229 - val_accuracy: 0.1339\n",
            "Epoch 75/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1365 - accuracy: 0.2816 - val_loss: 4.4240 - val_accuracy: 0.1301\n",
            "Epoch 76/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1324 - accuracy: 0.2838 - val_loss: 4.4098 - val_accuracy: 0.1349\n",
            "Epoch 77/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1334 - accuracy: 0.2814 - val_loss: 4.4609 - val_accuracy: 0.1326\n",
            "Epoch 78/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1266 - accuracy: 0.2808 - val_loss: 4.3275 - val_accuracy: 0.1523\n",
            "Epoch 79/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1083 - accuracy: 0.2847 - val_loss: 4.3791 - val_accuracy: 0.1374\n",
            "Epoch 80/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1138 - accuracy: 0.2876 - val_loss: 4.5046 - val_accuracy: 0.1302\n",
            "Epoch 81/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.1219 - accuracy: 0.2850 - val_loss: 4.3540 - val_accuracy: 0.1406\n",
            "Epoch 82/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.0930 - accuracy: 0.2874 - val_loss: 4.3821 - val_accuracy: 0.1353\n",
            "Epoch 83/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.0977 - accuracy: 0.2896 - val_loss: 4.4203 - val_accuracy: 0.1392\n",
            "Epoch 84/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.0926 - accuracy: 0.2893 - val_loss: 4.3648 - val_accuracy: 0.1373\n",
            "Epoch 85/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.0747 - accuracy: 0.2931 - val_loss: 4.4448 - val_accuracy: 0.1362\n",
            "Epoch 86/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.0873 - accuracy: 0.2933 - val_loss: 4.4094 - val_accuracy: 0.1340\n",
            "Epoch 87/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.0854 - accuracy: 0.2910 - val_loss: 4.4901 - val_accuracy: 0.1346\n",
            "Epoch 88/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.0812 - accuracy: 0.2921 - val_loss: 4.4816 - val_accuracy: 0.1355\n",
            "Epoch 89/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.0800 - accuracy: 0.2934 - val_loss: 4.3900 - val_accuracy: 0.1472\n",
            "Epoch 90/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.0657 - accuracy: 0.2922 - val_loss: 4.3242 - val_accuracy: 0.1370\n",
            "Epoch 91/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.0790 - accuracy: 0.2912 - val_loss: 4.3330 - val_accuracy: 0.1417\n",
            "Epoch 92/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.0736 - accuracy: 0.2925 - val_loss: 4.4753 - val_accuracy: 0.1364\n",
            "Epoch 93/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.0698 - accuracy: 0.2947 - val_loss: 4.3716 - val_accuracy: 0.1444\n",
            "Epoch 94/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.0670 - accuracy: 0.2934 - val_loss: 4.3977 - val_accuracy: 0.1336\n",
            "Epoch 95/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.0453 - accuracy: 0.2967 - val_loss: 4.4252 - val_accuracy: 0.1360\n",
            "Epoch 96/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.0525 - accuracy: 0.2981 - val_loss: 4.4521 - val_accuracy: 0.1320\n",
            "Epoch 97/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.0417 - accuracy: 0.2969 - val_loss: 4.5111 - val_accuracy: 0.1329\n",
            "Epoch 98/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.0415 - accuracy: 0.2974 - val_loss: 4.3726 - val_accuracy: 0.1436\n",
            "Epoch 99/100\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 3.0458 - accuracy: 0.2971 - val_loss: 4.3869 - val_accuracy: 0.1388\n",
            "Epoch 100/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.0469 - accuracy: 0.2970 - val_loss: 4.5228 - val_accuracy: 0.1338\n",
            "test accuracy:  0.1546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B54irevQWphD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Examining loss on TensorBoard\n",
        "%tensorboard --logdir logs/scalars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjCT6dtGXuU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}